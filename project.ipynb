{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5544dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/apollo2506/eurosat-dataset/versions/6\n"
     ]
    }
   ],
   "source": [
    "import kagglehub, os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"apollo2506/eurosat-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027ea2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "\n",
    "from src.datasets import EuroSATDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622f1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.backbones.resnet import ResNet\n",
    "from src.models.heads import FFN\n",
    "\n",
    "class EuroSATModel(nn.Module):\n",
    "    def __init__(self, backbone, head):\n",
    "        super(EuroSATModel, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, input, target):\n",
    "        logits = self.forward(input)\n",
    "        loss = self.criterion(logits, target)\n",
    "        return loss\n",
    "    \n",
    "    def forward_train(self, x, target):\n",
    "        img = x['image']\n",
    "        logits = self.forward(img)\n",
    "        loss = self.criterion(logits, target)\n",
    "        return logits, loss\n",
    "    \n",
    "    def forward_test(self, x):\n",
    "        img = x['image']\n",
    "        logits = self.forward(img)\n",
    "        return logits\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward_test(x)\n",
    "        return torch.argmax(logits, dim=1)\n",
    "    \n",
    "model = EuroSATModel(\n",
    "    backbone=ResNet(idims=3, odims=64, arch=(2, 2, 2, 2), base_dims=32), \n",
    "    head=FFN(idims=64, odims=10, hidden_dims=64, dropout=0.5, nlayers=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, average_precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from src.runner.utils import progress_bar\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, model, device, num_classes, class_names=None, save_dir = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): Trained model for inference.\n",
    "            device (str or torch.device): 'cpu' or 'cuda'.\n",
    "            num_classes (int): Number of target classes.\n",
    "            class_names (list[str], optional): Names of classes for plots.\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.device = torch.device(device)\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names or [str(i) for i in range(num_classes)]\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def predict(self, dataloader):\n",
    "        \"\"\"\n",
    "        Runs model inference on a DataLoader.\n",
    "        Returns:\n",
    "            y_true (np.ndarray): True labels shape (N,).\n",
    "            y_pred (np.ndarray): Predicted labels shape (N,).\n",
    "            y_scores (np.ndarray): Predicted probabilities shape (N, num_classes).\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        y_true, y_pred, y_scores = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                imgs = batch['image'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "                logits = self.model(imgs)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                preds = probs.argmax(dim=1)\n",
    "\n",
    "                progress_bar(\n",
    "                    iteration=i + 1,\n",
    "                    total_iterations=len(dataloader),\n",
    "                    prefix=\"Evaluating\",\n",
    "                    postfix=f\" {(i+1/len(dataloader)):.2f}%\",\n",
    "                    style=\"arrow\"\n",
    "                )\n",
    "\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "                y_scores.extend(probs.cpu().numpy())\n",
    "\n",
    "        return np.array(y_true), np.array(y_pred), np.array(y_scores)\n",
    "\n",
    "    def compute_f1(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"Compute F1 score.\"\"\"\n",
    "        return f1_score(y_true, y_pred, average=average)\n",
    "\n",
    "    def compute_map(self, y_true, y_scores):\n",
    "        \"\"\"\n",
    "        Compute mean Average Precision (mAP) for multiclass.\n",
    "        Returns:\n",
    "            mean_ap (float): Mean of per-class AP.\n",
    "            ap_per_class (np.ndarray): AP for each class.\n",
    "        \"\"\"\n",
    "        # Binarize labels for one-vs-rest\n",
    "        y_true_bin = label_binarize(y_true, classes=list(range(self.num_classes)))\n",
    "        ap_per_class = average_precision_score(y_true_bin, y_scores, average=None)\n",
    "        mean_ap = np.mean(ap_per_class)\n",
    "        return mean_ap, ap_per_class\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, normalize=True):\n",
    "        \"\"\"\n",
    "        Plots the confusion matrix.\n",
    "        Args:\n",
    "            y_true (array): True labels.\n",
    "            y_pred (array): Predicted labels.\n",
    "            normalize (bool): Whether to normalize by row sums.\n",
    "        Returns:\n",
    "            fig: Matplotlib figure object.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "        # Setup labels\n",
    "        ax.set(\n",
    "            xticks=np.arange(self.num_classes),\n",
    "            yticks=np.arange(self.num_classes),\n",
    "            xticklabels=self.class_names,\n",
    "            yticklabels=self.class_names,\n",
    "            ylabel='True label',\n",
    "            xlabel='Predicted label',\n",
    "            title='Confusion Matrix'\n",
    "        )\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "        # Annotate cells\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(self.num_classes):\n",
    "            for j in range(self.num_classes):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha='center', va='center',\n",
    "                        color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a60042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.runner.utils import progress_bar\n",
    "\n",
    "class Runner:\n",
    "    def __init__(self, model: nn.Module,\n",
    "                 loading_cfg: dict,\n",
    "                 data_cfg: dict,\n",
    "                 optim_cfg: dict,\n",
    "                 save_dir: str = None,\n",
    "                 device: str = 'cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.model  = model.to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), **optim_cfg)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_data = EuroSATDataset(**data_cfg, split='train')\n",
    "        self.val_data   = EuroSATDataset(**data_cfg, split='validation')\n",
    "        self.test_data  = EuroSATDataset(**data_cfg, split='test')\n",
    "\n",
    "        self.batch_size = loading_cfg['batch_size']\n",
    "\n",
    "        self.history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    def run(self,\n",
    "            mode: str = 'train',\n",
    "            val_interval: int= 10,\n",
    "            log_interval: int= 10,\n",
    "            epochs: int = 100,\n",
    "            start_epoch: int = 1):\n",
    "        if mode == 'train':\n",
    "            return self._train_loop(start_epoch, epochs, val_interval, log_interval)\n",
    "\n",
    "        elif mode == 'validation':\n",
    "            return self.evaluate(self.val_data, batch_size=1)\n",
    "\n",
    "        elif mode == 'test':\n",
    "            return self.evaluate(self.test_data, batch_size=self.batch_size)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be 'train', 'validation', or 'test'.\")\n",
    "        \n",
    "        \n",
    "\n",
    "    def _train_loop(self, start, epochs, val_interval, log_interval):\n",
    "        train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        for epoch in range(start, epochs):\n",
    "            train_loss = self._train_epoch(train_loader, epoch=epoch, total_epochs=epochs, log_interval=log_interval)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "\n",
    "            if epoch % val_interval == 0:\n",
    "                val_loss = self.evaluate(self.val_data, batch_size=self.batch_size, loss=True)\n",
    "                self.history['val_loss'].append(val_loss)\n",
    "                \n",
    "\n",
    "        return self.history\n",
    "\n",
    "    def _train_epoch(self, loader, epoch, total_epochs, log_interval=10):\n",
    "        self.model.train()\n",
    "        total_loss = 0.\n",
    "        total_batches = len(loader)\n",
    "\n",
    "        for i, batch in enumerate(loader):\n",
    "            imgs = batch['image'].to(self.device)\n",
    "            labels = batch['label'].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(imgs)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "            if i % log_interval == 0:\n",
    "                progress_bar(\n",
    "                    epoch=epoch,\n",
    "                    total_epochs=total_epochs,\n",
    "                    iteration=i+1,\n",
    "                    total_iterations=total_batches,\n",
    "                    vars={\n",
    "                        'loss': loss.item(),\n",
    "                        'lr': self.optimizer.param_groups[0]['lr'],\n",
    "                    },)                \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(loader)\n",
    "\n",
    "    def evaluate(self, dataset, batch_size, loss=False):\n",
    "        evaluator = Evaluator(self.model, self.device, num_classes=dataset.num_classes, class_names=dataset.class_names)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        y_true, y_pred, y_scores = evaluator.predict(dataloader)\n",
    "        if loss:\n",
    "            val_loss = self.criterion(torch.tensor(y_scores), torch.tensor(y_true)).item()\n",
    "        else:\n",
    "            val_loss = None\n",
    "        f1 = evaluator.compute_f1(y_true, y_pred)\n",
    "        mean_ap, ap_per_class = evaluator.compute_map(y_true, y_scores)\n",
    "\n",
    "        if evaluator.save_dir:\n",
    "            fig = evaluator.plot_confusion_matrix(y_true, y_pred)\n",
    "            fig.savefig(os.path.join(evaluator.save_dir, 'confusion_matrix.png'))\n",
    "            plt.close(fig)\n",
    "        \n",
    "        print(f\"F1 Score: {f1:.4f}, Mean Average Precision (mAP): {mean_ap:.4f}\") \n",
    "\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a865c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "loading_cfg = {\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "}\n",
    "\n",
    "data_cfg = {\n",
    "    'root_dir': os.path.join(path, 'EuroSAT'),\n",
    "    'transform': transform,\n",
    "}\n",
    "\n",
    "optim_cfg = {\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "}\n",
    "\n",
    "runner = Runner(model=model, loading_cfg=loading_cfg, data_cfg=data_cfg, optim_cfg=optim_cfg, device='cuda:2', save_dir='results/eurosat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47346b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Epoch 01/10 | Iter 19/19 | [██████████] |  | loss: 1.8676 | lr: 1.0000e-03\n",
      "Epoch [2/10], Train Loss: 2.1220\n",
      "\n",
      "Evaluating | Iter 6/6 | [>>>>>>>>>>] |  5.166666666666667:.2f%%%\n",
      "F1 Score: 0.0426, Mean Average Precision (mAP): 0.1892\n",
      " | Epoch 02/10 | Iter 1/19 | [----------] |  | loss: 1.8404 | lr: 1.0000e-03"
     ]
    }
   ],
   "source": [
    "runner.run(mode='train', val_interval=1, log_interval=1, epochs=10, start_epoch=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
