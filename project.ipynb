{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5544dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/apollo2506/eurosat-dataset/versions/6\n"
     ]
    }
   ],
   "source": [
    "import kagglehub, os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"apollo2506/eurosat-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdaa86a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No seed provided, using initial seed: 1971015095\n",
      "==================================\n",
      "     Model Parameters Summary     \n",
      "----------------------------------\n",
      "Trainable params     | 5,857,878\n",
      "Non-trainable params |         0\n",
      "Total params         | 5,857,878\n",
      "- Backbone params    | 1,582,668\n",
      "- Head params        | 4,275,210\n",
      "==================================\n",
      "Epoch 001/100 | Iter 19/19 | [██████████] |  | loss: 1.3130 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 2.8764 --> F1: 0.1023 | mAP: 0.2196\n",
      "Model saved to results/eurosat/run_20250612-220000/best_model.pth\n",
      "Best model saved at epoch 1 with val_loss 2.2235\n",
      "Epoch 002/100 | Iter 19/19 | [██████████] |  | loss: 1.0885 | lr: 1.0000e-03\n",
      "Evaluating | Iter 0201/5400 | [----------] |  3.72% | val_loss: 2.3240"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     30\u001b[39m model_cfg = {\n\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mEuroSATModel\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbackbone_cfg\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     }\n\u001b[32m     48\u001b[39m }\n\u001b[32m     50\u001b[39m runner = Runner(model=model_cfg, dataloader_cfg=loading_cfg, dataset=data_cfg, optim=optim_cfg, device=\u001b[33m'\u001b[39m\u001b[33mcuda:2\u001b[39m\u001b[33m'\u001b[39m, work_dir=\u001b[33m'\u001b[39m\u001b[33mresults/eurosat\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/runner/runner.py:138\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, mode, val_interval, log_interval, epochs, start_epoch)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03mMain entry point for running the model.\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m    dict: History of training/validation metrics.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluate(\u001b[38;5;28mself\u001b[39m.val_data, batch_size=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/runner/runner.py:168\u001b[39m, in \u001b[36mRunner._train_loop\u001b[39m\u001b[34m(self, start, epochs, val_interval, log_interval, abort_condition)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28mself\u001b[39m.history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % val_interval == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     evals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_dir:\n\u001b[32m    171\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m evals[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m] < \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m], default=\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/runner/runner.py:314\u001b[39m, in \u001b[36mRunner.evaluate\u001b[39m\u001b[34m(self, dataset, epoch, batch_size, loss)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, epoch=\u001b[38;5;28;01mNone\u001b[39;00m, batch_size=\u001b[32m1\u001b[39m, loss=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    312\u001b[39m     evaluator = build_module(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mBaseEvaluator\u001b[39m\u001b[33m'\u001b[39m, device=\u001b[38;5;28mself\u001b[39m.device, batch_size=batch_size, dataset=dataset, model=\u001b[38;5;28mself\u001b[39m.model), EVALUATORS) \u001b[38;5;66;03m# Build evaluator from config\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     y_true, y_pred, y_scores = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#predict labels and scores\u001b[39;00m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss:\n\u001b[32m    316\u001b[39m         val_loss = \u001b[38;5;28mself\u001b[39m.criterion(torch.tensor(y_scores), torch.tensor(y_true)).item() \u001b[38;5;66;03m# calculate loss if requested (for model saving and overfitting detection)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/evaluators/base_evaluator.py:50\u001b[39m, in \u001b[36mBaseEvaluator.predict\u001b[39m\u001b[34m(self, loss, log_interval)\u001b[39m\n\u001b[32m     48\u001b[39m imgs = batch[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m].to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     49\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m probs = torch.softmax(logits, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     53\u001b[39m preds = probs.argmax(dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/modules/models/EuroSATModel.py:18\u001b[39m, in \u001b[36mEuroSATModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.pool(x)\n\u001b[32m     20\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/modules/backbones/resnet.py:54\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03mForward pass of the ResNet model.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m    torch.Tensor: Output tensor of shape (batch_size, out_fear).\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/modules/backbones/utils/basic_block.py:40\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Optional dropout *after* the second ReLU\u001b[39;00m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m.dropout = nn.Dropout(dropout_rate) \u001b[38;5;28;01mif\u001b[39;00m (dropout_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     41\u001b[39m     identity = x\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# First conv → BN → ReLU\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "import src\n",
    "\n",
    "from src.runner import Runner\n",
    "import os\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "loading_cfg = {\n",
    "    'batch_size': 1024,\n",
    "    'num_workers': 4,\n",
    "}\n",
    "\n",
    "data_cfg = {\n",
    "    'type': 'EuroSATDataset'\n",
    "}\n",
    "\n",
    "optim_cfg = {\n",
    "    'type': 'Adam',\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "}\n",
    "\n",
    "\n",
    "model_cfg = {\n",
    "    'type': 'EuroSATModel',\n",
    "    'backbone_cfg': {\n",
    "        'type': 'ResNet',\n",
    "        'idims': 3,\n",
    "        'odims': 64,\n",
    "        'base_dims': 12,\n",
    "        'arch': [2,2,2,2],\n",
    "        'dropout': 0.2,\n",
    "    },\n",
    "    'head_cfg': {\n",
    "        'type': 'FFN',\n",
    "        'idims': 64,\n",
    "        'odims': 10,  # EuroSAT has 10 classes\n",
    "        'hidden_dims': 1024,\n",
    "        'nlayers':6,\n",
    "        'dropout': 0.2,\n",
    "    }\n",
    "}\n",
    "\n",
    "runner = Runner(model=model_cfg, dataloader_cfg=loading_cfg, dataset=data_cfg, optim=optim_cfg, device='cuda:2', work_dir='results/eurosat')\n",
    "runner.run(mode='train', val_interval=1, log_interval=1, epochs=100, start_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba8a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = {\n",
    "    'type': 'ImageNetDataset',\n",
    "}\n",
    "\n",
    "import src\n",
    "from src.build.registry import build_module, DATASETS\n",
    "\n",
    "dataset = build_module(data_cfg, DATASETS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_cfg = dict(\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "eurosat_cfg = dict(\n",
    "    type='EuroSATDataset',\n",
    "    transform=[\n",
    "        dict(type='Resize', size=(128, 128)),\n",
    "        dict(type='ToTensor'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imagenet_cfg = dict(\n",
    "    type='ImageNetDataset',\n",
    "    transform=[\n",
    "        dict(type='Resize', size=(128, 128)),\n",
    "        dict(type='ToTensor'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optim_cfg = dict(\n",
    "    type='Adam',\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "backbone_cfg = dict(\n",
    "    type='ResNet',\n",
    "    idims=3,\n",
    "    odims=64,\n",
    "    base_dims=12,\n",
    "    arch=[2, 2, 2, 2],\n",
    "    dropout=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe20147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No seed provided, using initial seed: 951366024\n",
      "==================================\n",
      "     Model Parameters Summary     \n",
      "----------------------------------\n",
      "Trainable params     | 6,052,628\n",
      "Non-trainable params |         0\n",
      "Total params         | 6,052,628\n",
      "- Backbone params    | 1,582,668\n",
      "- Head params        | 4,469,960\n",
      "==================================\n",
      "Epoch 001/100 | Iter 98/98 | [██████████] |  | loss: 4.9387 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.9496 --> F1: 0.0038 | mAP: 0.0196\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 1 with val_loss 5.2939\n",
      "Epoch 002/100 | Iter 98/98 | [██████████] |  | loss: 4.6264 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.6816 --> F1: 0.0169 | mAP: 0.0325\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 2 with val_loss 5.2881\n",
      "Epoch 003/100 | Iter 98/98 | [██████████] |  | loss: 4.4499 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.5399 --> F1: 0.0194 | mAP: 0.0434\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 3 with val_loss 5.2814\n",
      "Epoch 004/100 | Iter 98/98 | [██████████] |  | loss: 4.2718 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.3676 --> F1: 0.0387 | mAP: 0.0605\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 4 with val_loss 5.2746\n",
      "Epoch 005/100 | Iter 98/98 | [██████████] |  | loss: 3.9372 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.1586 --> F1: 0.0668 | mAP: 0.0834\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 5 with val_loss 5.2595\n",
      "Epoch 006/100 | Iter 98/98 | [██████████] |  | loss: 3.7724 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.0903 --> F1: 0.0761 | mAP: 0.0986\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 6 with val_loss 5.2568\n",
      "Epoch 007/100 | Iter 98/98 | [██████████] |  | loss: 3.6768 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.9100 --> F1: 0.0946 | mAP: 0.1130\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 7 with val_loss 5.2444\n",
      "Epoch 008/100 | Iter 98/98 | [██████████] |  | loss: 3.5423 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.6651 --> F1: 0.1324 | mAP: 0.1426\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 8 with val_loss 5.2222\n",
      "Epoch 009/100 | Iter 98/98 | [██████████] |  | loss: 3.4023 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.6475 --> F1: 0.1345 | mAP: 0.1572\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 9 with val_loss 5.2162\n",
      "Epoch 010/100 | Iter 98/98 | [██████████] |  | loss: 3.4430 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.5131 --> F1: 0.1680 | mAP: 0.1831\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 10 with val_loss 5.1962\n",
      "Epoch 011/100 | Iter 98/98 | [██████████] |  | loss: 3.2653 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.5030 --> F1: 0.1813 | mAP: 0.1946\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 11 with val_loss 5.1885\n",
      "Epoch 012/100 | Iter 98/98 | [██████████] |  | loss: 3.0000 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.4998 --> F1: 0.1935 | mAP: 0.1995\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 12 with val_loss 5.1825\n",
      "Epoch 013/100 | Iter 98/98 | [██████████] |  | loss: 2.9200 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.3275 --> F1: 0.2095 | mAP: 0.2213\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 13 with val_loss 5.1657\n",
      "Epoch 014/100 | Iter 98/98 | [██████████] |  | loss: 2.9241 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.3498 --> F1: 0.2168 | mAP: 0.2319\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 14 with val_loss 5.1598\n",
      "Epoch 015/100 | Iter 98/98 | [██████████] |  | loss: 2.7659 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.4375 --> F1: 0.2127 | mAP: 0.2220\n",
      "Epoch 016/100 | Iter 98/98 | [██████████] |  | loss: 2.6490 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.3946 --> F1: 0.2310 | mAP: 0.2368\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 16 with val_loss 5.1501\n",
      "Epoch 017/100 | Iter 98/98 | [██████████] |  | loss: 2.5400 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.5669 --> F1: 0.2143 | mAP: 0.2308\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 17 with val_loss 5.1448\n",
      "Epoch 018/100 | Iter 98/98 | [██████████] |  | loss: 2.4740 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.5096 --> F1: 0.2196 | mAP: 0.2359\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 18 with val_loss 5.1408\n",
      "Epoch 019/100 | Iter 98/98 | [██████████] |  | loss: 2.2557 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.4252 --> F1: 0.2349 | mAP: 0.2405\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 19 with val_loss 5.1283\n",
      "Epoch 020/100 | Iter 98/98 | [██████████] |  | loss: 2.2115 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.6082 --> F1: 0.2333 | mAP: 0.2379\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 20 with val_loss 5.1170\n",
      "Epoch 021/100 | Iter 98/98 | [██████████] |  | loss: 2.0713 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.4691 --> F1: 0.2451 | mAP: 0.2449\n",
      "Epoch 022/100 | Iter 98/98 | [██████████] |  | loss: 1.8016 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 3.5526 --> F1: 0.2545 | mAP: 0.2533\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 22 with val_loss 5.0995\n",
      "Epoch 023/100 | Iter 98/98 | [██████████] |  | loss: 1.6851 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.0265 --> F1: 0.2290 | mAP: 0.2268\n",
      "Epoch 024/100 | Iter 98/98 | [██████████] |  | loss: 1.7073 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.5123 --> F1: 0.2176 | mAP: 0.2157\n",
      "Epoch 025/100 | Iter 98/98 | [██████████] |  | loss: 1.4786 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.7816 --> F1: 0.2111 | mAP: 0.2090\n",
      "Epoch 026/100 | Iter 98/98 | [██████████] |  | loss: 1.4901 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.2443 --> F1: 0.2445 | mAP: 0.2327\n",
      "Model saved to results/imagenet/run_20250612-152058/best_model.pth\n",
      "Best model saved at epoch 26 with val_loss 5.0958\n",
      "Epoch 027/100 | Iter 98/98 | [██████████] |  | loss: 1.3629 | lr: 1.0000e-03\n",
      "Evaluating | Iter 10000/10000 | [>>>>>>>>>>] |  100.00% | val_loss: 4.8952 --> F1: 0.2285 | mAP: 0.2126\n",
      "Early stopping: no drop ≥0.05 in last 10 epochs of val_loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [5.094094870041828,\n",
       "  4.806673035329702,\n",
       "  4.586937018803188,\n",
       "  4.346366293576299,\n",
       "  4.0821913821356635,\n",
       "  3.8712936591128915,\n",
       "  3.7060899101957983,\n",
       "  3.556691439784303,\n",
       "  3.4093872138432095,\n",
       "  3.278604208206644,\n",
       "  3.142603443593395,\n",
       "  3.0176034411605523,\n",
       "  2.89690422281927,\n",
       "  2.782175973970063,\n",
       "  2.67751898084368,\n",
       "  2.5509630733606765,\n",
       "  2.4380312355197207,\n",
       "  2.322100651507475,\n",
       "  2.2175288954559638,\n",
       "  2.084393141221027,\n",
       "  1.9632532268154377,\n",
       "  1.8317359114179805,\n",
       "  1.7253172044851341,\n",
       "  1.6063980241211093,\n",
       "  1.499154152918835,\n",
       "  1.4132710366832966,\n",
       "  1.2965002789789317],\n",
       " 'val_loss': [5.2938995361328125,\n",
       "  5.288149833679199,\n",
       "  5.281394004821777,\n",
       "  5.274620532989502,\n",
       "  5.25952672958374,\n",
       "  5.2568206787109375,\n",
       "  5.244368553161621,\n",
       "  5.222179412841797,\n",
       "  5.216206073760986,\n",
       "  5.196222305297852,\n",
       "  5.188464641571045,\n",
       "  5.182450294494629,\n",
       "  5.16572904586792,\n",
       "  5.1597676277160645,\n",
       "  5.160167217254639,\n",
       "  5.150108814239502,\n",
       "  5.144759654998779,\n",
       "  5.140834808349609,\n",
       "  5.12827730178833,\n",
       "  5.117044925689697,\n",
       "  5.118008613586426,\n",
       "  5.099483966827393,\n",
       "  5.108674049377441,\n",
       "  5.127358436584473,\n",
       "  5.115180015563965,\n",
       "  5.095769882202148,\n",
       "  5.105329513549805],\n",
       " 'f1': [0.003819838863863764,\n",
       "  0.016918750708078967,\n",
       "  0.01940732876690472,\n",
       "  0.038705901781820165,\n",
       "  0.06681316965885102,\n",
       "  0.0760694861446985,\n",
       "  0.09457043386626308,\n",
       "  0.132434520329079,\n",
       "  0.13452257577739796,\n",
       "  0.16804600850224038,\n",
       "  0.18129599664017026,\n",
       "  0.1934591057217649,\n",
       "  0.20948095899683544,\n",
       "  0.2168064355668371,\n",
       "  0.2127200523618372,\n",
       "  0.23102086439489025,\n",
       "  0.214344524079686,\n",
       "  0.21964333401668906,\n",
       "  0.2348835298913589,\n",
       "  0.23329025007652923,\n",
       "  0.24508923737026295,\n",
       "  0.2545479177449939,\n",
       "  0.22903387033144998,\n",
       "  0.2175867758757142,\n",
       "  0.21107003569225552,\n",
       "  0.24445243449938922,\n",
       "  0.22849044795673773],\n",
       " 'mean_ap': [np.float64(0.01955539462889507),\n",
       "  np.float64(0.03253803217027798),\n",
       "  np.float64(0.043445448172104904),\n",
       "  np.float64(0.06049244527582167),\n",
       "  np.float64(0.08344858729088056),\n",
       "  np.float64(0.09860165320549313),\n",
       "  np.float64(0.1130372765486267),\n",
       "  np.float64(0.1425698170623212),\n",
       "  np.float64(0.15715892219668026),\n",
       "  np.float64(0.18310535332135702),\n",
       "  np.float64(0.19455773437676477),\n",
       "  np.float64(0.19946146660676278),\n",
       "  np.float64(0.22134790602494891),\n",
       "  np.float64(0.2318771232771222),\n",
       "  np.float64(0.22200478024375236),\n",
       "  np.float64(0.23675126801127924),\n",
       "  np.float64(0.23076941971706696),\n",
       "  np.float64(0.2359074957139792),\n",
       "  np.float64(0.24046504416359504),\n",
       "  np.float64(0.23791487320420746),\n",
       "  np.float64(0.24486137098177335),\n",
       "  np.float64(0.2533420299555872),\n",
       "  np.float64(0.22678435020920645),\n",
       "  np.float64(0.21573907345412605),\n",
       "  np.float64(0.20895974657675992),\n",
       "  np.float64(0.23267984353808344),\n",
       "  np.float64(0.2126185924104248)],\n",
       " 'ap_per_class': [array([0.03832751, 0.010275  , 0.02101675, 0.01230974, 0.03821515,\n",
       "         0.00798632, 0.01205016, 0.00962876, 0.01772994, 0.01343749,\n",
       "         0.00848119, 0.01475686, 0.00773789, 0.13909297, 0.02026219,\n",
       "         0.0113931 , 0.01009521, 0.01177626, 0.02897899, 0.00766166,\n",
       "         0.03102572, 0.00599443, 0.01419965, 0.02832403, 0.01009115,\n",
       "         0.01092181, 0.00956917, 0.00992854, 0.00809617, 0.00862698,\n",
       "         0.01083287, 0.01515589, 0.01786936, 0.01126626, 0.00822276,\n",
       "         0.01332298, 0.04959445, 0.03381521, 0.0474437 , 0.06561114,\n",
       "         0.01685825, 0.00918738, 0.01446293, 0.10161724, 0.02978507,\n",
       "         0.05970624, 0.00823954, 0.00737254, 0.0123918 , 0.01068594,\n",
       "         0.01230355, 0.01594734, 0.01356682, 0.01974216, 0.00760996,\n",
       "         0.01192959, 0.02007475, 0.02355238, 0.00977611, 0.00993237,\n",
       "         0.01903202, 0.01292099, 0.02231433, 0.00859397, 0.00644517,\n",
       "         0.00826175, 0.03960157, 0.00647016, 0.01164038, 0.00637136,\n",
       "         0.01150185, 0.0418035 , 0.01293381, 0.00815757, 0.01714826,\n",
       "         0.00776411, 0.00971605, 0.01224096, 0.02261778, 0.0084819 ,\n",
       "         0.00515294, 0.01322334, 0.02368738, 0.01302959, 0.0172324 ,\n",
       "         0.00549814, 0.00820055, 0.00773227, 0.00612508, 0.01251141,\n",
       "         0.0177673 , 0.0125349 , 0.01037124, 0.01693725, 0.01272816,\n",
       "         0.01914739, 0.02578877, 0.00748091, 0.01176259, 0.00996393,\n",
       "         0.00804763, 0.03039752, 0.00764804, 0.00793164, 0.01136129,\n",
       "         0.01729176, 0.01827711, 0.01417319, 0.00852821, 0.01228674,\n",
       "         0.01060336, 0.00825365, 0.03075748, 0.01123389, 0.01688259,\n",
       "         0.01123387, 0.01189299, 0.01014842, 0.01806824, 0.01573722,\n",
       "         0.01487758, 0.0129822 , 0.00885438, 0.01054347, 0.02103883,\n",
       "         0.00823591, 0.00782643, 0.00786908, 0.00674982, 0.00967171,\n",
       "         0.03893643, 0.00962318, 0.00909168, 0.01224703, 0.00960365,\n",
       "         0.0090075 , 0.0162514 , 0.0133709 , 0.00926587, 0.00594579,\n",
       "         0.00625488, 0.00935113, 0.00821823, 0.01969522, 0.01036099,\n",
       "         0.02060436, 0.00982822, 0.00668989, 0.0141684 , 0.00640092,\n",
       "         0.01553756, 0.0066722 , 0.03598842, 0.01378988, 0.03823489,\n",
       "         0.00847958, 0.01048464, 0.01943645, 0.00728582, 0.00711866,\n",
       "         0.00704921, 0.00929465, 0.02724716, 0.01247138, 0.00866855,\n",
       "         0.01195176, 0.02187598, 0.00955943, 0.00681746, 0.01133729,\n",
       "         0.02720393, 0.008207  , 0.00650737, 0.01627528, 0.01872508,\n",
       "         0.02152133, 0.01147423, 0.04305189, 0.03405069, 0.0136751 ,\n",
       "         0.01205391, 0.06210789, 0.01695548, 0.01692033, 0.0434321 ,\n",
       "         0.01144641, 0.20301063, 0.1152075 , 0.0479158 , 0.02835163,\n",
       "         0.02822915, 0.10370038, 0.03210096, 0.02005781, 0.03752025,\n",
       "         0.02535663, 0.02225318, 0.04767609, 0.06266894, 0.03304075]),\n",
       "  array([0.06001524, 0.01923186, 0.01893442, 0.02504772, 0.05198291,\n",
       "         0.01523642, 0.02882393, 0.02094732, 0.01408806, 0.01791396,\n",
       "         0.01157656, 0.01630098, 0.01095884, 0.35665026, 0.01173369,\n",
       "         0.01793828, 0.00987965, 0.01256438, 0.07816858, 0.00872219,\n",
       "         0.0240525 , 0.00779782, 0.02593448, 0.09340576, 0.01190921,\n",
       "         0.01429972, 0.0166805 , 0.01029877, 0.01400312, 0.01128312,\n",
       "         0.01238282, 0.02157966, 0.01402607, 0.01904714, 0.05741973,\n",
       "         0.01889271, 0.06490848, 0.02185396, 0.07233486, 0.03719642,\n",
       "         0.02107231, 0.01075488, 0.01871351, 0.05335645, 0.0501515 ,\n",
       "         0.09155679, 0.01257148, 0.0154285 , 0.02056288, 0.02185433,\n",
       "         0.02088066, 0.02707687, 0.03843679, 0.01864932, 0.01526095,\n",
       "         0.02278034, 0.03851008, 0.02963952, 0.01007472, 0.04279943,\n",
       "         0.05319623, 0.0161947 , 0.03908294, 0.03074883, 0.00776782,\n",
       "         0.00900367, 0.02077506, 0.01104087, 0.01613512, 0.00697883,\n",
       "         0.03042179, 0.04685923, 0.03390164, 0.01419479, 0.02075351,\n",
       "         0.01465917, 0.0069601 , 0.01150919, 0.03149948, 0.00763008,\n",
       "         0.0097055 , 0.02182412, 0.03477707, 0.01843847, 0.03535764,\n",
       "         0.01408518, 0.01748869, 0.0118401 , 0.00882886, 0.02357879,\n",
       "         0.08767602, 0.03692388, 0.00693334, 0.02578767, 0.04130051,\n",
       "         0.01974176, 0.062044  , 0.0102374 , 0.01012432, 0.00674805,\n",
       "         0.01355213, 0.10764935, 0.00856869, 0.01637544, 0.01746121,\n",
       "         0.03881014, 0.01341413, 0.03813398, 0.01116871, 0.01779894,\n",
       "         0.01393078, 0.02237336, 0.03364345, 0.01211085, 0.02738892,\n",
       "         0.13731005, 0.02342862, 0.01910468, 0.017738  , 0.01900599,\n",
       "         0.04369517, 0.02269552, 0.01199314, 0.02546695, 0.1566324 ,\n",
       "         0.00722318, 0.01335803, 0.01256184, 0.04760544, 0.00887703,\n",
       "         0.01663693, 0.01055595, 0.01689847, 0.02639874, 0.0085551 ,\n",
       "         0.01438642, 0.01548331, 0.02131918, 0.03634864, 0.01036462,\n",
       "         0.01096119, 0.03704761, 0.01273058, 0.02084709, 0.00812958,\n",
       "         0.13403801, 0.01918739, 0.00752314, 0.03103855, 0.01104821,\n",
       "         0.02402613, 0.02206207, 0.02777854, 0.04515896, 0.05342565,\n",
       "         0.01536981, 0.01000358, 0.02596641, 0.01225176, 0.00614043,\n",
       "         0.0085175 , 0.01331135, 0.03499855, 0.03661256, 0.02410695,\n",
       "         0.03736129, 0.04347956, 0.03839101, 0.01070378, 0.04825146,\n",
       "         0.05185468, 0.01186443, 0.011536  , 0.0333037 , 0.01797587,\n",
       "         0.01457975, 0.02886613, 0.03749939, 0.04125065, 0.02605143,\n",
       "         0.01960883, 0.0580523 , 0.04871701, 0.01910035, 0.04472373,\n",
       "         0.01157639, 0.22953787, 0.13696203, 0.05167726, 0.07028644,\n",
       "         0.04266057, 0.20461034, 0.10315017, 0.01907011, 0.05309584,\n",
       "         0.03822338, 0.04147896, 0.05901137, 0.09697429, 0.02890718]),\n",
       "  array([0.05772963, 0.03740861, 0.02870572, 0.02159832, 0.03852424,\n",
       "         0.01355127, 0.03582351, 0.03675884, 0.01416797, 0.0233251 ,\n",
       "         0.02177741, 0.03132741, 0.02977705, 0.43765276, 0.05270201,\n",
       "         0.03220005, 0.01708796, 0.01591332, 0.07303928, 0.01132529,\n",
       "         0.02437936, 0.01391583, 0.079673  , 0.14714283, 0.01733208,\n",
       "         0.01840395, 0.05339318, 0.01620978, 0.03967061, 0.01370439,\n",
       "         0.01865148, 0.03060934, 0.02115047, 0.0299873 , 0.06045657,\n",
       "         0.02647044, 0.0559555 , 0.04177554, 0.04155033, 0.07538688,\n",
       "         0.0274685 , 0.01327854, 0.02041489, 0.03796969, 0.12326461,\n",
       "         0.08770039, 0.01938802, 0.01550836, 0.02945191, 0.01560159,\n",
       "         0.03403669, 0.03339629, 0.03482465, 0.01631227, 0.01724865,\n",
       "         0.03336091, 0.03424105, 0.11670012, 0.02839678, 0.03001751,\n",
       "         0.0426553 , 0.01514866, 0.03360929, 0.01977437, 0.00988271,\n",
       "         0.01035663, 0.05375584, 0.00853389, 0.03680509, 0.01371716,\n",
       "         0.05328821, 0.09340324, 0.01402139, 0.02009841, 0.04726667,\n",
       "         0.0109314 , 0.00914326, 0.02130078, 0.0252325 , 0.00775987,\n",
       "         0.01008328, 0.0197868 , 0.04944869, 0.01876202, 0.01860949,\n",
       "         0.01824449, 0.02323177, 0.07040221, 0.0083307 , 0.02093753,\n",
       "         0.08961967, 0.03504038, 0.00895898, 0.0578341 , 0.08354552,\n",
       "         0.02463545, 0.06097346, 0.01842933, 0.01377542, 0.01405746,\n",
       "         0.01539133, 0.11998253, 0.00984497, 0.03213402, 0.0184057 ,\n",
       "         0.05462504, 0.01604474, 0.09882393, 0.01329215, 0.0216741 ,\n",
       "         0.01569457, 0.01853701, 0.03730094, 0.0139242 , 0.04376276,\n",
       "         0.11744995, 0.06583635, 0.01338419, 0.0723372 , 0.0171739 ,\n",
       "         0.02790139, 0.05309591, 0.02122011, 0.02848539, 0.19492408,\n",
       "         0.01206032, 0.0119441 , 0.01193603, 0.03109609, 0.01525196,\n",
       "         0.01594851, 0.01658308, 0.02650707, 0.1466469 , 0.0105762 ,\n",
       "         0.02405206, 0.02046748, 0.02628829, 0.02642214, 0.01004728,\n",
       "         0.00978649, 0.01405038, 0.01841986, 0.0518039 , 0.00947659,\n",
       "         0.17600627, 0.03030328, 0.01526812, 0.06889919, 0.01207571,\n",
       "         0.02671487, 0.0155806 , 0.02370711, 0.11641438, 0.11410388,\n",
       "         0.01203494, 0.01806928, 0.03197911, 0.01760088, 0.00612643,\n",
       "         0.01257772, 0.01800378, 0.03422383, 0.03030612, 0.02986239,\n",
       "         0.0895523 , 0.11138326, 0.03918957, 0.00893647, 0.03542181,\n",
       "         0.07696193, 0.01280731, 0.01751595, 0.05851346, 0.01474339,\n",
       "         0.01547243, 0.06894494, 0.03740834, 0.03908574, 0.03122939,\n",
       "         0.01699155, 0.05404542, 0.07377186, 0.02394026, 0.1589494 ,\n",
       "         0.01403335, 0.21572889, 0.12546625, 0.03846526, 0.08981318,\n",
       "         0.04746642, 0.23997457, 0.11443836, 0.03476334, 0.06207224,\n",
       "         0.04341356, 0.09020792, 0.05923284, 0.19991178, 0.03258036]),\n",
       "  array([0.07596702, 0.07355235, 0.03649231, 0.06404517, 0.05489575,\n",
       "         0.01967555, 0.03875976, 0.03541282, 0.02731849, 0.04472835,\n",
       "         0.0200677 , 0.02577577, 0.03414358, 0.42661784, 0.11523025,\n",
       "         0.04755093, 0.01510997, 0.0284528 , 0.05445859, 0.03348302,\n",
       "         0.0443172 , 0.0246669 , 0.04458472, 0.2171354 , 0.02551035,\n",
       "         0.04611394, 0.08467174, 0.02066173, 0.02382957, 0.01566643,\n",
       "         0.019156  , 0.03468271, 0.01717998, 0.04419891, 0.0759551 ,\n",
       "         0.0424525 , 0.11034859, 0.03186398, 0.08346023, 0.0581623 ,\n",
       "         0.03155378, 0.01784925, 0.05828429, 0.06881229, 0.22593726,\n",
       "         0.09839392, 0.05042627, 0.03042571, 0.02535739, 0.02019359,\n",
       "         0.07441224, 0.03883545, 0.06087132, 0.02671127, 0.04919457,\n",
       "         0.02417502, 0.08323629, 0.1183718 , 0.02752453, 0.01610523,\n",
       "         0.0714581 , 0.07590078, 0.04206717, 0.01738888, 0.00975434,\n",
       "         0.0252892 , 0.02709824, 0.01224   , 0.03269506, 0.01950346,\n",
       "         0.08388558, 0.09811507, 0.03774358, 0.03256733, 0.0395607 ,\n",
       "         0.00908246, 0.01024283, 0.02166048, 0.08885061, 0.01332768,\n",
       "         0.01216068, 0.0488017 , 0.05331439, 0.02029083, 0.02176712,\n",
       "         0.03819841, 0.03862085, 0.04048428, 0.00732538, 0.0176809 ,\n",
       "         0.15155894, 0.04054375, 0.0154493 , 0.09498447, 0.08434174,\n",
       "         0.05368335, 0.06163906, 0.04709427, 0.02448744, 0.01071642,\n",
       "         0.01890877, 0.1775145 , 0.01205457, 0.07838488, 0.05211873,\n",
       "         0.07197412, 0.02114206, 0.14644467, 0.0313589 , 0.03532766,\n",
       "         0.01852598, 0.02762862, 0.03410983, 0.01897836, 0.04076486,\n",
       "         0.21775084, 0.0636672 , 0.01293546, 0.05916222, 0.02516892,\n",
       "         0.04467089, 0.08699383, 0.01155836, 0.02657022, 0.23212294,\n",
       "         0.01275961, 0.04755366, 0.01521903, 0.09802594, 0.05918877,\n",
       "         0.02019735, 0.01463503, 0.03127719, 0.32353066, 0.01647408,\n",
       "         0.01578715, 0.01703945, 0.01702063, 0.04041438, 0.01134901,\n",
       "         0.02315125, 0.01471454, 0.01804104, 0.08120863, 0.01376723,\n",
       "         0.16892764, 0.05567516, 0.03882862, 0.07009939, 0.01658328,\n",
       "         0.01840886, 0.02456254, 0.03560351, 0.1415998 , 0.13060413,\n",
       "         0.01048455, 0.02362802, 0.03227529, 0.01389558, 0.03572495,\n",
       "         0.01730221, 0.01815811, 0.05397706, 0.04728419, 0.04238405,\n",
       "         0.23023555, 0.1295119 , 0.11668779, 0.01255031, 0.05961044,\n",
       "         0.1127352 , 0.04999765, 0.01805072, 0.06476105, 0.06203385,\n",
       "         0.01602927, 0.1244119 , 0.05492575, 0.09142215, 0.03906745,\n",
       "         0.02087807, 0.06109212, 0.11535829, 0.0487    , 0.10231965,\n",
       "         0.0142321 , 0.23979053, 0.19265464, 0.07017197, 0.07219585,\n",
       "         0.08622944, 0.38483839, 0.18647447, 0.05955514, 0.07057486,\n",
       "         0.06591412, 0.15910703, 0.05797317, 0.23315817, 0.08743855]),\n",
       "  array([0.10882064, 0.09148865, 0.05243728, 0.05446296, 0.06628492,\n",
       "         0.02729381, 0.05930054, 0.05611979, 0.01939121, 0.03958708,\n",
       "         0.03051904, 0.02795533, 0.0231098 , 0.48186704, 0.17731697,\n",
       "         0.04248287, 0.029134  , 0.04063786, 0.13095678, 0.13943061,\n",
       "         0.03176339, 0.0243845 , 0.06731457, 0.31307568, 0.03777773,\n",
       "         0.05740924, 0.04928609, 0.04196429, 0.04659545, 0.03893111,\n",
       "         0.02227331, 0.04722884, 0.01520786, 0.07299145, 0.13646236,\n",
       "         0.04256453, 0.15888221, 0.04765633, 0.08034833, 0.08279181,\n",
       "         0.0290243 , 0.03101671, 0.04655938, 0.09999785, 0.37605318,\n",
       "         0.23433852, 0.07565211, 0.05594671, 0.0253132 , 0.02906892,\n",
       "         0.12118771, 0.03926052, 0.04875847, 0.03288943, 0.05806195,\n",
       "         0.01445299, 0.06841455, 0.18582515, 0.04137693, 0.02349478,\n",
       "         0.10069468, 0.12994879, 0.07440552, 0.01919819, 0.01648415,\n",
       "         0.05193183, 0.03503023, 0.02208378, 0.0680516 , 0.02691067,\n",
       "         0.14732288, 0.09095508, 0.03941158, 0.03794662, 0.07337774,\n",
       "         0.00808847, 0.02079554, 0.02002051, 0.12862329, 0.01673867,\n",
       "         0.01310055, 0.05016389, 0.13504185, 0.05012424, 0.02907558,\n",
       "         0.03218864, 0.06053984, 0.06442594, 0.00988428, 0.03453518,\n",
       "         0.20563555, 0.07304999, 0.03138112, 0.16580472, 0.17073856,\n",
       "         0.06646221, 0.09734818, 0.04580731, 0.04725225, 0.01083726,\n",
       "         0.02225867, 0.24202648, 0.01179966, 0.07261408, 0.07225605,\n",
       "         0.04418872, 0.01800791, 0.12468686, 0.0329726 , 0.04425836,\n",
       "         0.07826046, 0.08594092, 0.09354222, 0.0329603 , 0.04413647,\n",
       "         0.35635349, 0.05849415, 0.01506031, 0.23573385, 0.01988589,\n",
       "         0.04991076, 0.10215709, 0.02139568, 0.02770862, 0.24517785,\n",
       "         0.02062963, 0.1246902 , 0.02438144, 0.10458715, 0.07875642,\n",
       "         0.03280687, 0.01577671, 0.04159241, 0.28150131, 0.04018794,\n",
       "         0.01731831, 0.01934377, 0.02903172, 0.0481128 , 0.00925847,\n",
       "         0.06121022, 0.02372201, 0.02072026, 0.2146364 , 0.01203488,\n",
       "         0.22616948, 0.11568485, 0.08582494, 0.09405809, 0.02883318,\n",
       "         0.02923762, 0.04811083, 0.07575581, 0.16839289, 0.08139272,\n",
       "         0.01527083, 0.02735023, 0.02801613, 0.02757936, 0.02327909,\n",
       "         0.01746777, 0.03409646, 0.09672471, 0.06307926, 0.07082219,\n",
       "         0.19950802, 0.21019392, 0.07123473, 0.01317172, 0.06283381,\n",
       "         0.13918204, 0.05636568, 0.01905509, 0.1371237 , 0.05595139,\n",
       "         0.01605761, 0.32712099, 0.06057117, 0.18177337, 0.03723515,\n",
       "         0.03979664, 0.1052999 , 0.11564637, 0.056619  , 0.21759182,\n",
       "         0.01528167, 0.32432897, 0.298709  , 0.07596671, 0.19076614,\n",
       "         0.11603356, 0.48488425, 0.13036001, 0.11996157, 0.09587277,\n",
       "         0.08751852, 0.26448648, 0.05904494, 0.19155758, 0.11176384]),\n",
       "  array([0.20408198, 0.13578565, 0.06732323, 0.05241261, 0.11314834,\n",
       "         0.02513055, 0.14481008, 0.07580104, 0.05299486, 0.0893818 ,\n",
       "         0.03539121, 0.04667785, 0.03735262, 0.4371062 , 0.13052876,\n",
       "         0.02428508, 0.02245369, 0.07407961, 0.06818184, 0.14655736,\n",
       "         0.04429822, 0.03345109, 0.2027288 , 0.3403816 , 0.01870008,\n",
       "         0.09262237, 0.07161069, 0.02735165, 0.04348093, 0.03153103,\n",
       "         0.02296965, 0.07148102, 0.02142551, 0.04703385, 0.11370387,\n",
       "         0.09243797, 0.1484912 , 0.04537441, 0.10567301, 0.06210913,\n",
       "         0.01778897, 0.03289396, 0.08446889, 0.09791215, 0.49773042,\n",
       "         0.24251376, 0.1059171 , 0.0567001 , 0.03337693, 0.0545045 ,\n",
       "         0.1337092 , 0.074382  , 0.02567038, 0.07840329, 0.08557368,\n",
       "         0.03467631, 0.0993254 , 0.2294776 , 0.05400963, 0.02752925,\n",
       "         0.04523245, 0.14421913, 0.07172739, 0.01516915, 0.02329201,\n",
       "         0.04092873, 0.04766592, 0.01730268, 0.05666581, 0.02110595,\n",
       "         0.14171162, 0.0864457 , 0.03656921, 0.04603061, 0.07428836,\n",
       "         0.01233183, 0.01604815, 0.03420197, 0.25076417, 0.01607269,\n",
       "         0.01654501, 0.16144524, 0.15639335, 0.04205886, 0.02519688,\n",
       "         0.03310563, 0.18356163, 0.08628313, 0.01793688, 0.08199134,\n",
       "         0.18433147, 0.10185848, 0.02341143, 0.23535738, 0.18635782,\n",
       "         0.13978958, 0.09758744, 0.07256214, 0.09478063, 0.01541955,\n",
       "         0.02625069, 0.32245496, 0.0263827 , 0.12379126, 0.10391058,\n",
       "         0.04933922, 0.0343262 , 0.20327371, 0.08655253, 0.03713765,\n",
       "         0.05037932, 0.0618975 , 0.08508197, 0.02321797, 0.05051323,\n",
       "         0.5524429 , 0.08483202, 0.03332699, 0.19791986, 0.02579339,\n",
       "         0.05061988, 0.09075312, 0.02538119, 0.06010772, 0.26962925,\n",
       "         0.01385772, 0.21585034, 0.0244833 , 0.18912704, 0.10458437,\n",
       "         0.03152378, 0.01536039, 0.05784177, 0.27006635, 0.02494598,\n",
       "         0.03031458, 0.03124052, 0.02634823, 0.05394663, 0.01171496,\n",
       "         0.03532926, 0.0293746 , 0.025982  , 0.30535233, 0.03469056,\n",
       "         0.37313375, 0.14229882, 0.11186323, 0.13853755, 0.02524701,\n",
       "         0.03553639, 0.05425561, 0.05485528, 0.18056014, 0.09821297,\n",
       "         0.03219689, 0.02415552, 0.08222186, 0.04450751, 0.03144881,\n",
       "         0.02779969, 0.03641378, 0.10110375, 0.05945256, 0.10805296,\n",
       "         0.20373829, 0.30147104, 0.20311789, 0.02938029, 0.07065923,\n",
       "         0.15175336, 0.03825802, 0.02965123, 0.11010679, 0.1238916 ,\n",
       "         0.01481057, 0.20337591, 0.0889836 , 0.22771607, 0.04354324,\n",
       "         0.05316093, 0.05108882, 0.13947754, 0.1118869 , 0.09659773,\n",
       "         0.0219884 , 0.16139155, 0.20808989, 0.10030881, 0.22134696,\n",
       "         0.09633511, 0.48432312, 0.102723  , 0.32483473, 0.10839882,\n",
       "         0.10857592, 0.30838714, 0.06840562, 0.20788312, 0.09491337]),\n",
       "  array([0.27200897, 0.20888754, 0.04837687, 0.05937475, 0.09055358,\n",
       "         0.02588153, 0.34310272, 0.10680744, 0.13879901, 0.09135681,\n",
       "         0.04995075, 0.09474327, 0.06629998, 0.42185754, 0.1845884 ,\n",
       "         0.04789007, 0.03429593, 0.0679428 , 0.10199516, 0.15917192,\n",
       "         0.06741956, 0.03505343, 0.22807672, 0.40704753, 0.04463026,\n",
       "         0.12785354, 0.09640186, 0.03333657, 0.06175981, 0.03048894,\n",
       "         0.06827576, 0.08919412, 0.02938555, 0.06053947, 0.10948145,\n",
       "         0.08649578, 0.33628794, 0.09270217, 0.20055357, 0.09559834,\n",
       "         0.03673965, 0.03548199, 0.08067119, 0.14061097, 0.56453037,\n",
       "         0.29008483, 0.14613254, 0.07717205, 0.03980211, 0.03180099,\n",
       "         0.183453  , 0.06811295, 0.06332618, 0.05678939, 0.05895949,\n",
       "         0.05708035, 0.10603266, 0.21839687, 0.09453649, 0.02605494,\n",
       "         0.03319774, 0.1352441 , 0.06256603, 0.0317574 , 0.01690739,\n",
       "         0.04287493, 0.06494316, 0.01996441, 0.07047457, 0.05192003,\n",
       "         0.13563349, 0.11702238, 0.07180128, 0.04390054, 0.0658023 ,\n",
       "         0.02060172, 0.01940052, 0.0199731 , 0.35972274, 0.02440887,\n",
       "         0.02590254, 0.11713136, 0.12183278, 0.04751019, 0.03871233,\n",
       "         0.0734727 , 0.14827744, 0.18225583, 0.0206148 , 0.12458669,\n",
       "         0.28690264, 0.06802155, 0.04068656, 0.2323645 , 0.18203488,\n",
       "         0.10629668, 0.08427899, 0.06780652, 0.07434346, 0.01319142,\n",
       "         0.03408403, 0.40133667, 0.06178233, 0.14083803, 0.09850287,\n",
       "         0.0568781 , 0.04269752, 0.27917336, 0.05866713, 0.03673706,\n",
       "         0.08547895, 0.11961541, 0.09967818, 0.05546184, 0.07921947,\n",
       "         0.39671985, 0.08138232, 0.037837  , 0.28504911, 0.03327631,\n",
       "         0.05029209, 0.09709957, 0.03945223, 0.04645481, 0.27898157,\n",
       "         0.02444528, 0.208577  , 0.0463755 , 0.13480972, 0.07753435,\n",
       "         0.06364113, 0.01685929, 0.06024099, 0.22780986, 0.02667876,\n",
       "         0.02916768, 0.03703404, 0.03270372, 0.04700015, 0.01872051,\n",
       "         0.10449107, 0.06767076, 0.01853222, 0.49582947, 0.04905639,\n",
       "         0.31694472, 0.17363349, 0.06701257, 0.13857047, 0.02399217,\n",
       "         0.02230544, 0.06609038, 0.05732437, 0.20997669, 0.11761764,\n",
       "         0.04890612, 0.03528764, 0.0493774 , 0.03858009, 0.02910513,\n",
       "         0.03396732, 0.0439121 , 0.08843731, 0.06589785, 0.08670874,\n",
       "         0.39003511, 0.1753069 , 0.07731998, 0.02530736, 0.10420664,\n",
       "         0.19706437, 0.07849367, 0.02978438, 0.10504476, 0.15350311,\n",
       "         0.03054828, 0.19336339, 0.11450898, 0.12949159, 0.04425017,\n",
       "         0.07170457, 0.08012952, 0.14731608, 0.11435745, 0.21498254,\n",
       "         0.03900293, 0.25657174, 0.3072836 , 0.0899752 , 0.19384499,\n",
       "         0.07574248, 0.38852623, 0.17333883, 0.46939663, 0.11757671,\n",
       "         0.06648838, 0.32884335, 0.07924436, 0.17334577, 0.11945695]),\n",
       "  array([0.34486272, 0.37102497, 0.07805605, 0.08191885, 0.13998255,\n",
       "         0.03903175, 0.28088141, 0.15089154, 0.1867027 , 0.1547165 ,\n",
       "         0.05693785, 0.132425  , 0.11713563, 0.48238864, 0.25416955,\n",
       "         0.02702497, 0.02951142, 0.11753941, 0.0834502 , 0.17731567,\n",
       "         0.08554663, 0.0580475 , 0.27944166, 0.48678775, 0.06489259,\n",
       "         0.16733439, 0.17830565, 0.04740826, 0.05503992, 0.03689842,\n",
       "         0.08328458, 0.12927811, 0.03402489, 0.08763935, 0.17029151,\n",
       "         0.12020133, 0.33738382, 0.14616868, 0.15660164, 0.09832773,\n",
       "         0.04247993, 0.05765955, 0.09139792, 0.14069372, 0.59385492,\n",
       "         0.27701748, 0.09383676, 0.11377787, 0.04889761, 0.05859586,\n",
       "         0.25564485, 0.13124842, 0.04166514, 0.08959688, 0.07393851,\n",
       "         0.06546324, 0.12976309, 0.2530455 , 0.15085422, 0.02489107,\n",
       "         0.11157135, 0.22376395, 0.08261761, 0.05605749, 0.03829723,\n",
       "         0.07863443, 0.0638611 , 0.03808981, 0.17324025, 0.02753078,\n",
       "         0.20810737, 0.13924385, 0.09412128, 0.08943927, 0.07798549,\n",
       "         0.02456812, 0.03027223, 0.02833895, 0.42883499, 0.01840472,\n",
       "         0.02073521, 0.19059647, 0.13143443, 0.06329085, 0.06847015,\n",
       "         0.0933303 , 0.18799021, 0.16614722, 0.02161407, 0.12478263,\n",
       "         0.24697435, 0.24926187, 0.0688165 , 0.26444207, 0.20640837,\n",
       "         0.0983777 , 0.09847003, 0.08609391, 0.09271017, 0.03011067,\n",
       "         0.02757935, 0.27478533, 0.06067954, 0.45911128, 0.08559501,\n",
       "         0.07405383, 0.07224961, 0.23738208, 0.12565615, 0.08537106,\n",
       "         0.12847988, 0.17592463, 0.07919121, 0.03692665, 0.0924893 ,\n",
       "         0.55378502, 0.15234628, 0.05569141, 0.39516397, 0.05442714,\n",
       "         0.0620574 , 0.11669072, 0.03074293, 0.06904574, 0.35297996,\n",
       "         0.02393968, 0.25334612, 0.05348905, 0.16037059, 0.21966743,\n",
       "         0.07453626, 0.02056507, 0.08377378, 0.41736241, 0.05562881,\n",
       "         0.03108764, 0.04571342, 0.04645675, 0.06437683, 0.02274555,\n",
       "         0.08209226, 0.06369186, 0.02329197, 0.56540629, 0.04516042,\n",
       "         0.52815488, 0.13812709, 0.14572006, 0.13322172, 0.02805939,\n",
       "         0.03692029, 0.13157331, 0.18805669, 0.20699122, 0.10973671,\n",
       "         0.04378084, 0.036527  , 0.07791479, 0.0367638 , 0.05960761,\n",
       "         0.03598375, 0.03126457, 0.11511339, 0.09421567, 0.10530326,\n",
       "         0.43846939, 0.33775037, 0.20534761, 0.02234466, 0.12997292,\n",
       "         0.18285246, 0.07646044, 0.06138146, 0.18077031, 0.1863463 ,\n",
       "         0.02494267, 0.2878445 , 0.10452631, 0.29312318, 0.06237041,\n",
       "         0.07140507, 0.10542702, 0.18740172, 0.19773391, 0.24969331,\n",
       "         0.03713164, 0.30357351, 0.28117832, 0.09408061, 0.21278985,\n",
       "         0.12766692, 0.52670162, 0.14870296, 0.51443786, 0.11527499,\n",
       "         0.13706873, 0.41413649, 0.05567453, 0.16641191, 0.0725939 ]),\n",
       "  array([0.54389837, 0.36484322, 0.07391501, 0.11448826, 0.17847195,\n",
       "         0.03512501, 0.32671022, 0.12340182, 0.17303263, 0.14998385,\n",
       "         0.05288963, 0.09898588, 0.17220473, 0.51504166, 0.21822825,\n",
       "         0.08165967, 0.03555792, 0.19138861, 0.11717775, 0.14793692,\n",
       "         0.13618728, 0.14082776, 0.29835194, 0.59516671, 0.06577404,\n",
       "         0.23595408, 0.20907369, 0.06849869, 0.07430977, 0.06359804,\n",
       "         0.09232977, 0.23376259, 0.05706313, 0.07488598, 0.18577047,\n",
       "         0.16710503, 0.32857503, 0.14559   , 0.19640122, 0.15766726,\n",
       "         0.04612481, 0.07687893, 0.12100252, 0.18311901, 0.63160132,\n",
       "         0.30706944, 0.1707795 , 0.14904237, 0.05155437, 0.06949842,\n",
       "         0.31245586, 0.11211635, 0.06447895, 0.10822798, 0.07258342,\n",
       "         0.07012842, 0.14018572, 0.25751742, 0.18218343, 0.07803934,\n",
       "         0.16295012, 0.26559251, 0.08368259, 0.05321275, 0.03792944,\n",
       "         0.08265614, 0.108522  , 0.04806319, 0.08177673, 0.03671465,\n",
       "         0.27546274, 0.16649766, 0.04948955, 0.06402204, 0.15267234,\n",
       "         0.02910975, 0.03027916, 0.0454849 , 0.4805115 , 0.01958857,\n",
       "         0.01818193, 0.19491268, 0.16816128, 0.05503963, 0.07131535,\n",
       "         0.13290545, 0.18831438, 0.16680255, 0.02264323, 0.18860065,\n",
       "         0.17461761, 0.20099124, 0.06752493, 0.27383148, 0.27489342,\n",
       "         0.11451781, 0.08743103, 0.10008599, 0.11708145, 0.03040027,\n",
       "         0.03917174, 0.38982269, 0.03550357, 0.48534279, 0.07693842,\n",
       "         0.08413482, 0.08092662, 0.31147595, 0.13137477, 0.07588643,\n",
       "         0.05704766, 0.14229581, 0.07255438, 0.05415008, 0.1095092 ,\n",
       "         0.70475011, 0.15766589, 0.10056674, 0.39997101, 0.04953948,\n",
       "         0.06714985, 0.14540489, 0.04680159, 0.09928049, 0.29277939,\n",
       "         0.02655934, 0.23179684, 0.0421129 , 0.14580788, 0.20888595,\n",
       "         0.05442176, 0.02584544, 0.0637264 , 0.37732258, 0.13396497,\n",
       "         0.03427153, 0.03321427, 0.03831112, 0.06635529, 0.05259902,\n",
       "         0.06454266, 0.04495848, 0.021904  , 0.57911165, 0.04146449,\n",
       "         0.62801193, 0.17413237, 0.1503504 , 0.17967375, 0.03447609,\n",
       "         0.02643171, 0.09548525, 0.13868083, 0.21785144, 0.15755447,\n",
       "         0.05556844, 0.04309089, 0.08915973, 0.06651038, 0.04139537,\n",
       "         0.04299999, 0.03518838, 0.17790817, 0.07352866, 0.12812157,\n",
       "         0.42963789, 0.35054851, 0.20654637, 0.01760039, 0.13556903,\n",
       "         0.2277398 , 0.16442022, 0.05850984, 0.16762947, 0.1901879 ,\n",
       "         0.02065495, 0.22406553, 0.13507143, 0.19661927, 0.04977487,\n",
       "         0.0985822 , 0.1023342 , 0.20578446, 0.29916854, 0.20150502,\n",
       "         0.07886919, 0.32887536, 0.25925835, 0.10228308, 0.24119111,\n",
       "         0.1725918 , 0.47453509, 0.26008723, 0.48211864, 0.12823386,\n",
       "         0.15333937, 0.34863382, 0.07548002, 0.22771035, 0.19439442]),\n",
       "  array([0.44545621, 0.45143491, 0.12209122, 0.15437212, 0.20391659,\n",
       "         0.04581752, 0.34700093, 0.09347269, 0.36389142, 0.14808351,\n",
       "         0.07953807, 0.14513765, 0.28871648, 0.48330571, 0.35063682,\n",
       "         0.08660942, 0.03202468, 0.19245396, 0.15349309, 0.20529714,\n",
       "         0.09908091, 0.14616149, 0.41229302, 0.62876497, 0.03004705,\n",
       "         0.17924267, 0.1629194 , 0.0453156 , 0.03882854, 0.04204351,\n",
       "         0.12227935, 0.21802267, 0.05892863, 0.0743945 , 0.13276724,\n",
       "         0.17255904, 0.53617573, 0.16447539, 0.18362037, 0.20492365,\n",
       "         0.06187239, 0.12468554, 0.13458857, 0.23728974, 0.66250988,\n",
       "         0.46751116, 0.20879417, 0.13183125, 0.05698792, 0.07005723,\n",
       "         0.30700734, 0.09026859, 0.09394245, 0.13044696, 0.07485994,\n",
       "         0.15728744, 0.12473478, 0.21179345, 0.33860989, 0.05081541,\n",
       "         0.18408887, 0.28889947, 0.13217251, 0.08277492, 0.0468769 ,\n",
       "         0.09124697, 0.16922348, 0.04705705, 0.16420498, 0.03508691,\n",
       "         0.29447624, 0.15004798, 0.08603926, 0.07885586, 0.13758126,\n",
       "         0.0466961 , 0.03454322, 0.03237863, 0.53543837, 0.03038346,\n",
       "         0.04454491, 0.37424204, 0.18254063, 0.06374383, 0.12317001,\n",
       "         0.15185952, 0.26432448, 0.1876103 , 0.02035301, 0.10382644,\n",
       "         0.26096235, 0.21226249, 0.0735508 , 0.30836799, 0.33440634,\n",
       "         0.18312974, 0.10418105, 0.14921242, 0.17183242, 0.04653561,\n",
       "         0.05643596, 0.48277913, 0.07266403, 0.57143449, 0.08335735,\n",
       "         0.08905025, 0.07834802, 0.4038019 , 0.11786097, 0.02946701,\n",
       "         0.13706665, 0.20658306, 0.06736249, 0.05630815, 0.15080164,\n",
       "         0.6573659 , 0.1474415 , 0.17102833, 0.45948646, 0.09323824,\n",
       "         0.08949575, 0.15873473, 0.04704733, 0.11206789, 0.51190092,\n",
       "         0.03087366, 0.28426053, 0.04935176, 0.21195193, 0.20487786,\n",
       "         0.1277864 , 0.04215677, 0.14274946, 0.46914554, 0.15116685,\n",
       "         0.03400151, 0.03259401, 0.06308153, 0.05832976, 0.0272207 ,\n",
       "         0.13567606, 0.08464112, 0.02733785, 0.58303886, 0.04744647,\n",
       "         0.4896199 , 0.29647822, 0.10561976, 0.2495353 , 0.054201  ,\n",
       "         0.02049121, 0.10942737, 0.2079897 , 0.28229439, 0.10679241,\n",
       "         0.07531825, 0.03948486, 0.09390428, 0.0661725 , 0.03011115,\n",
       "         0.10225772, 0.04405378, 0.21911416, 0.07976697, 0.1578539 ,\n",
       "         0.59101983, 0.3787883 , 0.18531717, 0.02132297, 0.16475285,\n",
       "         0.23007142, 0.21528075, 0.1057902 , 0.17120035, 0.26207863,\n",
       "         0.02366186, 0.34471876, 0.16187944, 0.32377931, 0.10698306,\n",
       "         0.06117573, 0.06090106, 0.20627721, 0.32218307, 0.32632674,\n",
       "         0.08502668, 0.33395918, 0.35396703, 0.09656616, 0.33217247,\n",
       "         0.19808048, 0.39742472, 0.28588095, 0.52265102, 0.14091658,\n",
       "         0.18497259, 0.45482304, 0.09006327, 0.23888943, 0.14264792]),\n",
       "  array([0.60182565, 0.44897342, 0.14293808, 0.20861937, 0.14474793,\n",
       "         0.04140978, 0.38190702, 0.13417042, 0.4073032 , 0.17577842,\n",
       "         0.12214139, 0.19058393, 0.22377992, 0.57232566, 0.33462485,\n",
       "         0.06380282, 0.06320695, 0.23535139, 0.17441797, 0.21636037,\n",
       "         0.14858858, 0.20101542, 0.2996718 , 0.62701324, 0.08848664,\n",
       "         0.26144382, 0.19093914, 0.08168793, 0.13087954, 0.07616602,\n",
       "         0.08159258, 0.1555461 , 0.0809982 , 0.11122548, 0.15258036,\n",
       "         0.14433468, 0.47941472, 0.16485308, 0.21883867, 0.13071302,\n",
       "         0.06178121, 0.20417922, 0.13538832, 0.25790018, 0.69384087,\n",
       "         0.47676683, 0.17309182, 0.1729603 , 0.08980036, 0.09269742,\n",
       "         0.46118268, 0.10959155, 0.07740377, 0.17384455, 0.11886794,\n",
       "         0.10715812, 0.10360405, 0.22667588, 0.29277066, 0.06259674,\n",
       "         0.17474822, 0.24798427, 0.21396589, 0.04931455, 0.03787936,\n",
       "         0.09623642, 0.21259723, 0.03510094, 0.18746945, 0.03156383,\n",
       "         0.25306992, 0.27772615, 0.14003398, 0.05396086, 0.21236516,\n",
       "         0.02603881, 0.04232648, 0.02585979, 0.48991178, 0.02983288,\n",
       "         0.03323999, 0.49368892, 0.21431996, 0.0453195 , 0.16119799,\n",
       "         0.14793416, 0.3124899 , 0.20288305, 0.04455405, 0.15681469,\n",
       "         0.3028243 , 0.3471747 , 0.08168863, 0.27906627, 0.32669297,\n",
       "         0.17324983, 0.16762952, 0.12058077, 0.1084933 , 0.03793375,\n",
       "         0.03636758, 0.39484171, 0.06503757, 0.55240849, 0.09888449,\n",
       "         0.07383091, 0.0719585 , 0.44951842, 0.17153312, 0.03799661,\n",
       "         0.18727646, 0.28454491, 0.14291131, 0.06050974, 0.16454452,\n",
       "         0.69210139, 0.13663517, 0.18053326, 0.44296688, 0.06504442,\n",
       "         0.05442409, 0.15036146, 0.05474254, 0.16091531, 0.50790705,\n",
       "         0.05639686, 0.25591946, 0.05725536, 0.24590123, 0.22554975,\n",
       "         0.07744636, 0.01945054, 0.10587118, 0.40203628, 0.18451308,\n",
       "         0.04698994, 0.03007251, 0.06712233, 0.08537541, 0.04034391,\n",
       "         0.11999198, 0.0695061 , 0.05463957, 0.65592836, 0.05864923,\n",
       "         0.49552803, 0.29490271, 0.06968528, 0.26794451, 0.06102231,\n",
       "         0.02717839, 0.07540136, 0.26929125, 0.30993621, 0.13423638,\n",
       "         0.09233677, 0.03395923, 0.14551116, 0.09983562, 0.03059516,\n",
       "         0.04100936, 0.03884855, 0.22630367, 0.11129473, 0.28632617,\n",
       "         0.58961088, 0.42188433, 0.19849667, 0.02255933, 0.14058038,\n",
       "         0.27724585, 0.13317508, 0.05435925, 0.19548295, 0.22261401,\n",
       "         0.02076361, 0.37157114, 0.1686061 , 0.37202228, 0.08741701,\n",
       "         0.11217162, 0.08742528, 0.19733874, 0.26034983, 0.36256733,\n",
       "         0.17008475, 0.31840833, 0.3108696 , 0.09050178, 0.36512314,\n",
       "         0.21689035, 0.48261831, 0.23479916, 0.4855048 , 0.17775899,\n",
       "         0.14101828, 0.53828657, 0.08427789, 0.24704801, 0.14609084]),\n",
       "  array([0.56486522, 0.51344961, 0.1442853 , 0.13956565, 0.14012597,\n",
       "         0.05261196, 0.40698423, 0.13734806, 0.37244048, 0.204047  ,\n",
       "         0.10551885, 0.12909351, 0.31629786, 0.58718853, 0.28215188,\n",
       "         0.09688711, 0.03615807, 0.14480095, 0.13312327, 0.13935052,\n",
       "         0.09206255, 0.25286154, 0.32652326, 0.61763113, 0.0839092 ,\n",
       "         0.34068896, 0.17125265, 0.06790424, 0.10460136, 0.0632925 ,\n",
       "         0.15339268, 0.26451961, 0.08730645, 0.06686579, 0.11651493,\n",
       "         0.15608267, 0.53931764, 0.16202608, 0.20352271, 0.1734671 ,\n",
       "         0.06359409, 0.13973881, 0.16907361, 0.2704222 , 0.66662747,\n",
       "         0.4214586 , 0.13867277, 0.24312178, 0.05861676, 0.10415632,\n",
       "         0.46335792, 0.11055541, 0.2304516 , 0.15739903, 0.10114969,\n",
       "         0.07911501, 0.12506411, 0.2525471 , 0.34405143, 0.06013538,\n",
       "         0.28889772, 0.26751265, 0.16154576, 0.06858938, 0.03892985,\n",
       "         0.08782225, 0.16695555, 0.05937724, 0.13336893, 0.05049027,\n",
       "         0.22726338, 0.31488872, 0.10236017, 0.08142986, 0.14596564,\n",
       "         0.03578163, 0.03249988, 0.0345988 , 0.58463075, 0.03997977,\n",
       "         0.04073488, 0.39019678, 0.20793269, 0.07172938, 0.10703266,\n",
       "         0.14907628, 0.27984494, 0.14767951, 0.03332288, 0.15973912,\n",
       "         0.31975289, 0.29099288, 0.08128527, 0.3388171 , 0.32244891,\n",
       "         0.18423872, 0.07605607, 0.14133747, 0.24910557, 0.04978168,\n",
       "         0.04437766, 0.49929828, 0.08196131, 0.59137172, 0.12030977,\n",
       "         0.11769331, 0.0437567 , 0.41023731, 0.25451912, 0.03927766,\n",
       "         0.14182262, 0.17964565, 0.08293495, 0.06198418, 0.1085012 ,\n",
       "         0.68445925, 0.1007499 , 0.31161005, 0.37133737, 0.10352338,\n",
       "         0.07104402, 0.20473551, 0.04634352, 0.13844828, 0.54450805,\n",
       "         0.06340636, 0.29597249, 0.04165531, 0.29910022, 0.24750492,\n",
       "         0.08290801, 0.02877267, 0.12935507, 0.41965572, 0.20900807,\n",
       "         0.0750441 , 0.03522929, 0.0875806 , 0.13744864, 0.03085611,\n",
       "         0.16890509, 0.06605325, 0.09456321, 0.58523927, 0.04753359,\n",
       "         0.56222544, 0.33766972, 0.10991147, 0.19941077, 0.07177474,\n",
       "         0.03344881, 0.15940978, 0.1518184 , 0.28276332, 0.22333315,\n",
       "         0.13946663, 0.05125153, 0.15663491, 0.08325549, 0.04926063,\n",
       "         0.08486802, 0.07101167, 0.25235964, 0.07411212, 0.19826924,\n",
       "         0.57415382, 0.48030414, 0.21967099, 0.02032762, 0.13354928,\n",
       "         0.23701788, 0.14987109, 0.12043547, 0.24086522, 0.1988431 ,\n",
       "         0.02328145, 0.38939607, 0.15953994, 0.25610078, 0.12743167,\n",
       "         0.10465618, 0.1131608 , 0.21931157, 0.32721595, 0.33985734,\n",
       "         0.08456906, 0.32475082, 0.39931908, 0.13032264, 0.41296014,\n",
       "         0.16396104, 0.41965811, 0.29964424, 0.64116609, 0.14346148,\n",
       "         0.19674655, 0.44309492, 0.09009042, 0.2744195 , 0.18730067]),\n",
       "  array([0.54348246, 0.51084689, 0.15791718, 0.12291593, 0.19569393,\n",
       "         0.05488678, 0.38817173, 0.18309172, 0.46126316, 0.17687904,\n",
       "         0.13789215, 0.16701243, 0.40926354, 0.62794232, 0.39101467,\n",
       "         0.11840061, 0.05348249, 0.19742685, 0.08894322, 0.35146048,\n",
       "         0.15477487, 0.41311786, 0.35559501, 0.65163579, 0.13807814,\n",
       "         0.21478326, 0.185757  , 0.09709384, 0.14540478, 0.06432888,\n",
       "         0.17311777, 0.28461957, 0.12587946, 0.0876806 , 0.21304469,\n",
       "         0.1268448 , 0.57898558, 0.26744107, 0.15379446, 0.18985568,\n",
       "         0.07613573, 0.19881593, 0.18682928, 0.2758142 , 0.75376865,\n",
       "         0.59620668, 0.22456456, 0.19960651, 0.06638106, 0.08796077,\n",
       "         0.49528772, 0.10258769, 0.1343736 , 0.23580874, 0.07143169,\n",
       "         0.20173299, 0.13794264, 0.35202729, 0.38571636, 0.06983454,\n",
       "         0.27127895, 0.27825567, 0.17321871, 0.11390202, 0.05032631,\n",
       "         0.11933359, 0.19794913, 0.0807818 , 0.18635369, 0.11525988,\n",
       "         0.22279008, 0.29378766, 0.14885766, 0.07829984, 0.1927263 ,\n",
       "         0.04450809, 0.04431565, 0.03667038, 0.58030402, 0.05455156,\n",
       "         0.03343945, 0.47378461, 0.13072391, 0.06536479, 0.1671051 ,\n",
       "         0.18656334, 0.24600315, 0.18304306, 0.02777149, 0.13895907,\n",
       "         0.33104175, 0.34231641, 0.08188678, 0.3073636 , 0.32250008,\n",
       "         0.22430108, 0.13656516, 0.20097353, 0.16301108, 0.06281272,\n",
       "         0.06137487, 0.54957131, 0.09779225, 0.61831814, 0.17404621,\n",
       "         0.07628418, 0.06794129, 0.4626004 , 0.24067124, 0.06015669,\n",
       "         0.10488751, 0.35556519, 0.09190557, 0.06434539, 0.13590314,\n",
       "         0.60021274, 0.16805058, 0.29262578, 0.52153376, 0.14051697,\n",
       "         0.0749446 , 0.19691933, 0.06146533, 0.05332   , 0.52299596,\n",
       "         0.07622269, 0.29936215, 0.07529065, 0.27965235, 0.24951708,\n",
       "         0.10301301, 0.04874689, 0.06109631, 0.49565724, 0.18197308,\n",
       "         0.07234043, 0.03911712, 0.05911014, 0.08892418, 0.04263041,\n",
       "         0.08870793, 0.11486709, 0.06560818, 0.7191287 , 0.09527794,\n",
       "         0.59169382, 0.57541803, 0.10652814, 0.27383813, 0.10469163,\n",
       "         0.04123946, 0.07054516, 0.26775957, 0.3040492 , 0.2545523 ,\n",
       "         0.1560425 , 0.07640228, 0.14386626, 0.0940409 , 0.04221092,\n",
       "         0.05111143, 0.11649539, 0.14281894, 0.09498429, 0.17683227,\n",
       "         0.48124194, 0.45309984, 0.29790553, 0.02892492, 0.15315947,\n",
       "         0.2728263 , 0.26108872, 0.08687041, 0.28899315, 0.26942182,\n",
       "         0.0299811 , 0.43142978, 0.19755031, 0.41844976, 0.07641097,\n",
       "         0.08906712, 0.14010606, 0.26897124, 0.40162595, 0.35066107,\n",
       "         0.13050881, 0.35751589, 0.42072948, 0.17622872, 0.35187548,\n",
       "         0.28755429, 0.48145923, 0.35718624, 0.64386012, 0.21915731,\n",
       "         0.14787565, 0.48253008, 0.11951865, 0.24457392, 0.19426074]),\n",
       "  array([0.6193396 , 0.46066139, 0.15060189, 0.12447054, 0.22480556,\n",
       "         0.03994139, 0.40659445, 0.16015638, 0.43505296, 0.14256557,\n",
       "         0.16137229, 0.20524147, 0.22422446, 0.55703244, 0.40443944,\n",
       "         0.13506263, 0.05364321, 0.24872965, 0.14868745, 0.29067886,\n",
       "         0.15587086, 0.52083734, 0.398069  , 0.69724478, 0.12250996,\n",
       "         0.16645811, 0.18437523, 0.07783563, 0.20510175, 0.06482575,\n",
       "         0.10473646, 0.27743974, 0.10236173, 0.08806762, 0.26080332,\n",
       "         0.24035812, 0.54188862, 0.24286837, 0.22020539, 0.18180386,\n",
       "         0.07757322, 0.18315611, 0.15896875, 0.31573387, 0.70407428,\n",
       "         0.56963862, 0.30071107, 0.25059801, 0.04598642, 0.097644  ,\n",
       "         0.51861313, 0.1041232 , 0.24375782, 0.27811408, 0.13528388,\n",
       "         0.17130319, 0.18643558, 0.26119526, 0.37760148, 0.04411301,\n",
       "         0.34710808, 0.3706775 , 0.21917533, 0.08692849, 0.07393666,\n",
       "         0.0762515 , 0.27013241, 0.07114552, 0.24481311, 0.09813851,\n",
       "         0.18924647, 0.28164994, 0.0963511 , 0.1176587 , 0.19288503,\n",
       "         0.04029533, 0.0422614 , 0.03512045, 0.57534666, 0.05023382,\n",
       "         0.05175906, 0.51318274, 0.24206493, 0.12345596, 0.14975562,\n",
       "         0.19195672, 0.36470759, 0.24621208, 0.02472512, 0.20486767,\n",
       "         0.32292221, 0.38668588, 0.13918265, 0.3111946 , 0.32551403,\n",
       "         0.19521895, 0.11811702, 0.14736154, 0.18076368, 0.04601547,\n",
       "         0.03407656, 0.52103482, 0.06841121, 0.6046918 , 0.12355085,\n",
       "         0.1267442 , 0.05911158, 0.44687693, 0.2817082 , 0.06393648,\n",
       "         0.20758331, 0.33102432, 0.13768646, 0.07705569, 0.12292953,\n",
       "         0.70323641, 0.1864982 , 0.3115664 , 0.58250696, 0.08490605,\n",
       "         0.05419041, 0.22232549, 0.05586598, 0.12614751, 0.54435353,\n",
       "         0.02804888, 0.23819547, 0.08973512, 0.25786901, 0.2868553 ,\n",
       "         0.07420503, 0.03362539, 0.08113126, 0.46429635, 0.20411307,\n",
       "         0.09525746, 0.05284206, 0.08173444, 0.04981604, 0.06360789,\n",
       "         0.17394923, 0.10791289, 0.11115376, 0.72297397, 0.09611956,\n",
       "         0.62659394, 0.39690788, 0.11805521, 0.28738559, 0.100681  ,\n",
       "         0.06975385, 0.12133734, 0.29913358, 0.37553549, 0.19351677,\n",
       "         0.12891291, 0.05367213, 0.21879164, 0.08631377, 0.05737898,\n",
       "         0.06080813, 0.07333904, 0.29808824, 0.08710594, 0.23665526,\n",
       "         0.58453731, 0.58800831, 0.19853571, 0.0216558 , 0.15091771,\n",
       "         0.34093015, 0.18302411, 0.08589333, 0.29885853, 0.27969876,\n",
       "         0.05073392, 0.42776714, 0.1610438 , 0.48958757, 0.06909409,\n",
       "         0.0747876 , 0.15546196, 0.28105404, 0.40243386, 0.4745729 ,\n",
       "         0.09198099, 0.38083065, 0.36007843, 0.18223307, 0.40645754,\n",
       "         0.27881158, 0.5781663 , 0.44723089, 0.67611462, 0.26741614,\n",
       "         0.18452184, 0.48944095, 0.08447829, 0.25541459, 0.25561659]),\n",
       "  array([0.48136162, 0.41721509, 0.22990774, 0.13698081, 0.22735825,\n",
       "         0.04901317, 0.37320957, 0.14123632, 0.45319532, 0.21242002,\n",
       "         0.11342108, 0.14631605, 0.41254947, 0.69753362, 0.37356708,\n",
       "         0.10967375, 0.07001266, 0.20784735, 0.08099297, 0.26755158,\n",
       "         0.18534391, 0.41980027, 0.44848   , 0.67311104, 0.11408263,\n",
       "         0.34323844, 0.32774776, 0.13296865, 0.14948753, 0.07813258,\n",
       "         0.17618986, 0.30158826, 0.09970668, 0.08221206, 0.20022304,\n",
       "         0.20145814, 0.55866285, 0.23519578, 0.24088567, 0.19252764,\n",
       "         0.09671225, 0.15769683, 0.16106357, 0.24359124, 0.66674908,\n",
       "         0.60101414, 0.18756479, 0.2170712 , 0.05412713, 0.08384483,\n",
       "         0.53316505, 0.11152973, 0.25914173, 0.2588807 , 0.14299066,\n",
       "         0.25858973, 0.14897329, 0.40096446, 0.35502343, 0.0473685 ,\n",
       "         0.22603389, 0.27293116, 0.0781928 , 0.10855564, 0.06732306,\n",
       "         0.04589618, 0.30044104, 0.09642441, 0.10245142, 0.12708265,\n",
       "         0.2079296 , 0.31910817, 0.09572191, 0.08109412, 0.22848873,\n",
       "         0.04856459, 0.02865798, 0.06410603, 0.56219579, 0.04812144,\n",
       "         0.03544555, 0.47677644, 0.14435525, 0.1007923 , 0.17167827,\n",
       "         0.1443386 , 0.26502388, 0.18462368, 0.02826564, 0.22590428,\n",
       "         0.16572835, 0.40225751, 0.07165879, 0.29199595, 0.33675825,\n",
       "         0.18266702, 0.15349884, 0.22192805, 0.26124999, 0.05590213,\n",
       "         0.05503761, 0.58463876, 0.05120877, 0.65626764, 0.11266952,\n",
       "         0.1425381 , 0.06740324, 0.34961461, 0.21229765, 0.05234973,\n",
       "         0.15874663, 0.1443713 , 0.05238521, 0.09923548, 0.15512744,\n",
       "         0.60894826, 0.20383165, 0.34850502, 0.42825348, 0.10232115,\n",
       "         0.07320607, 0.30137226, 0.07183877, 0.08883592, 0.45817021,\n",
       "         0.09693939, 0.27024347, 0.08488961, 0.19419908, 0.26212515,\n",
       "         0.1080774 , 0.04039767, 0.06617017, 0.46699887, 0.20975252,\n",
       "         0.0576085 , 0.0524714 , 0.08436854, 0.10546525, 0.05065916,\n",
       "         0.11151195, 0.0386174 , 0.07753096, 0.66906621, 0.07056185,\n",
       "         0.57252204, 0.35997118, 0.10318375, 0.27371493, 0.13180557,\n",
       "         0.06823833, 0.09767912, 0.24961749, 0.29748298, 0.17085118,\n",
       "         0.12068247, 0.08915413, 0.16142338, 0.12016702, 0.03218672,\n",
       "         0.06043806, 0.05532801, 0.32822057, 0.09142015, 0.30048945,\n",
       "         0.65545257, 0.46193716, 0.18081864, 0.0239005 , 0.16330746,\n",
       "         0.37629998, 0.2539407 , 0.11293955, 0.31623698, 0.21462428,\n",
       "         0.06861854, 0.24721995, 0.18193512, 0.3022411 , 0.08615516,\n",
       "         0.08762027, 0.1773284 , 0.31615308, 0.4130062 , 0.28102558,\n",
       "         0.09644914, 0.38756923, 0.43284129, 0.16748127, 0.22935441,\n",
       "         0.21549641, 0.49333276, 0.46388478, 0.61166541, 0.23679251,\n",
       "         0.21380645, 0.53000681, 0.11152603, 0.2960312 , 0.23391349]),\n",
       "  array([0.64463548, 0.54970738, 0.2231983 , 0.20621921, 0.16451439,\n",
       "         0.04827717, 0.40181853, 0.14237917, 0.44834787, 0.20355695,\n",
       "         0.14629707, 0.15122015, 0.37913288, 0.68342183, 0.43635897,\n",
       "         0.09943842, 0.04108081, 0.29364452, 0.08533267, 0.34616541,\n",
       "         0.1395561 , 0.41614696, 0.49205074, 0.60672325, 0.09004112,\n",
       "         0.34323185, 0.26897352, 0.08880384, 0.19606337, 0.07660442,\n",
       "         0.12472104, 0.27055923, 0.0997091 , 0.10251186, 0.22860373,\n",
       "         0.1367924 , 0.52510572, 0.22022637, 0.3034494 , 0.17993405,\n",
       "         0.12140837, 0.21168363, 0.1724455 , 0.20960261, 0.6894054 ,\n",
       "         0.538798  , 0.22152616, 0.20164107, 0.05284866, 0.0824664 ,\n",
       "         0.49118653, 0.0798498 , 0.31780009, 0.22057355, 0.14282212,\n",
       "         0.26772392, 0.22990887, 0.27381528, 0.39093837, 0.06769791,\n",
       "         0.38938839, 0.35757929, 0.11522145, 0.09602696, 0.07823636,\n",
       "         0.10878445, 0.2648269 , 0.05424999, 0.15777509, 0.13678751,\n",
       "         0.25619805, 0.34541022, 0.13878626, 0.12099215, 0.29597797,\n",
       "         0.0470839 , 0.03240546, 0.06544994, 0.57781928, 0.07079241,\n",
       "         0.06293253, 0.52581819, 0.24754448, 0.11965158, 0.13354969,\n",
       "         0.21562434, 0.37042292, 0.19652796, 0.01804805, 0.17442026,\n",
       "         0.32159003, 0.28833501, 0.10245678, 0.25198953, 0.35861926,\n",
       "         0.23106687, 0.1269231 , 0.2147611 , 0.27782121, 0.07621269,\n",
       "         0.03214166, 0.57205799, 0.05201245, 0.66848941, 0.15326368,\n",
       "         0.17132233, 0.05989568, 0.45700515, 0.22041793, 0.0943693 ,\n",
       "         0.19369214, 0.3060715 , 0.15159835, 0.0627674 , 0.180978  ,\n",
       "         0.6722228 , 0.17583379, 0.32913966, 0.50538645, 0.07014055,\n",
       "         0.04838045, 0.26768182, 0.05860509, 0.1685585 , 0.59507303,\n",
       "         0.06141178, 0.27272464, 0.10460627, 0.25189713, 0.30139646,\n",
       "         0.09290472, 0.03018594, 0.08489033, 0.43117355, 0.21884443,\n",
       "         0.10367936, 0.09579554, 0.06277539, 0.12939197, 0.04504852,\n",
       "         0.16773366, 0.12636385, 0.10880935, 0.6426211 , 0.09624295,\n",
       "         0.62554422, 0.47680143, 0.11569288, 0.28899532, 0.12333852,\n",
       "         0.06608055, 0.08489111, 0.26665767, 0.4117349 , 0.24571441,\n",
       "         0.17385697, 0.11612063, 0.20377121, 0.10585627, 0.03816485,\n",
       "         0.05273564, 0.07159548, 0.27923293, 0.1140662 , 0.38800213,\n",
       "         0.64951577, 0.58674757, 0.20885442, 0.0187991 , 0.15444727,\n",
       "         0.35650675, 0.29567627, 0.08290674, 0.32659684, 0.1771545 ,\n",
       "         0.04498609, 0.48315583, 0.10667615, 0.2370777 , 0.09679816,\n",
       "         0.07618647, 0.11342454, 0.18191767, 0.34624018, 0.40288364,\n",
       "         0.14123053, 0.39327387, 0.44439701, 0.20898191, 0.41445274,\n",
       "         0.21945324, 0.57876732, 0.25382389, 0.64012817, 0.20142445,\n",
       "         0.20207127, 0.50950026, 0.16238157, 0.27301121, 0.20354404]),\n",
       "  array([0.54689967, 0.55672237, 0.20742559, 0.11932532, 0.23634963,\n",
       "         0.0534542 , 0.37756295, 0.2232793 , 0.42070861, 0.12728398,\n",
       "         0.16482633, 0.1986724 , 0.18193168, 0.66612107, 0.33576689,\n",
       "         0.1002516 , 0.05966167, 0.37116636, 0.10247381, 0.35380734,\n",
       "         0.1529933 , 0.48968079, 0.39752675, 0.65669644, 0.08825158,\n",
       "         0.29701314, 0.2230021 , 0.1368954 , 0.22439743, 0.0622708 ,\n",
       "         0.10200778, 0.29106255, 0.09394622, 0.06542285, 0.2030146 ,\n",
       "         0.19201555, 0.40324118, 0.1733378 , 0.15687591, 0.18111081,\n",
       "         0.142474  , 0.12774657, 0.17620825, 0.24926162, 0.66030383,\n",
       "         0.48419929, 0.33113944, 0.26577612, 0.07927904, 0.11013712,\n",
       "         0.40636411, 0.07906209, 0.26852138, 0.27566171, 0.08865369,\n",
       "         0.25761337, 0.10815684, 0.2976586 , 0.24687863, 0.0599648 ,\n",
       "         0.29919967, 0.29222516, 0.17181661, 0.10083703, 0.10916218,\n",
       "         0.07800508, 0.28199544, 0.06058287, 0.14483134, 0.11654233,\n",
       "         0.15787093, 0.37089625, 0.12648105, 0.05144237, 0.20066165,\n",
       "         0.08123261, 0.03619149, 0.05683493, 0.56682506, 0.03800088,\n",
       "         0.05496812, 0.60413582, 0.15382023, 0.11531647, 0.20111188,\n",
       "         0.21528591, 0.33889811, 0.22901614, 0.02959145, 0.26744747,\n",
       "         0.35884291, 0.36705394, 0.13650538, 0.17570589, 0.35116286,\n",
       "         0.23966182, 0.14022511, 0.19515816, 0.24638184, 0.05813861,\n",
       "         0.03037109, 0.52896808, 0.06867574, 0.64923669, 0.12051034,\n",
       "         0.11425302, 0.1164614 , 0.35895075, 0.31816771, 0.05412128,\n",
       "         0.1797715 , 0.3361213 , 0.11432893, 0.10143006, 0.09906765,\n",
       "         0.64175594, 0.17297355, 0.3188063 , 0.53692792, 0.15461799,\n",
       "         0.0793247 , 0.14922034, 0.09339512, 0.16362646, 0.49671342,\n",
       "         0.05576418, 0.25704573, 0.09840273, 0.28114927, 0.36243328,\n",
       "         0.12889371, 0.02217965, 0.06287461, 0.48106947, 0.19356911,\n",
       "         0.09385914, 0.07667788, 0.09805743, 0.07030336, 0.03830268,\n",
       "         0.16048712, 0.15318914, 0.1231449 , 0.56333246, 0.11661286,\n",
       "         0.65521165, 0.40194869, 0.07283591, 0.30658148, 0.09956411,\n",
       "         0.10478159, 0.12295808, 0.23667758, 0.25333779, 0.25175842,\n",
       "         0.17220835, 0.07295314, 0.18987316, 0.09409761, 0.0353961 ,\n",
       "         0.04980918, 0.1080299 , 0.33688118, 0.08780991, 0.28799904,\n",
       "         0.65462908, 0.61504314, 0.25644763, 0.01987983, 0.17206097,\n",
       "         0.39590841, 0.25598083, 0.05539712, 0.35798141, 0.23721577,\n",
       "         0.04183275, 0.30690905, 0.2381967 , 0.33176235, 0.10264907,\n",
       "         0.09568613, 0.10275036, 0.20407481, 0.40807509, 0.46113915,\n",
       "         0.09653594, 0.45898329, 0.41278818, 0.17429421, 0.43185946,\n",
       "         0.2293733 , 0.52191245, 0.29953069, 0.6050787 , 0.29287519,\n",
       "         0.17241497, 0.58239411, 0.14594071, 0.31459047, 0.19625642]),\n",
       "  array([0.59861708, 0.48186828, 0.21712366, 0.1740282 , 0.25304315,\n",
       "         0.06610547, 0.3273262 , 0.10496082, 0.50556785, 0.18765399,\n",
       "         0.14395692, 0.17515626, 0.25350655, 0.70096915, 0.39399449,\n",
       "         0.11249923, 0.0549041 , 0.34215788, 0.0990463 , 0.34909158,\n",
       "         0.18921807, 0.42644934, 0.34028538, 0.70301338, 0.09177188,\n",
       "         0.33996483, 0.27878281, 0.13626628, 0.17806314, 0.07394341,\n",
       "         0.10719728, 0.27491464, 0.0539834 , 0.11870984, 0.33609395,\n",
       "         0.23170581, 0.54379668, 0.2073285 , 0.21457298, 0.14419915,\n",
       "         0.1324344 , 0.1525031 , 0.16670498, 0.23255258, 0.77370446,\n",
       "         0.60375609, 0.23129006, 0.20046736, 0.08736038, 0.10243368,\n",
       "         0.51242107, 0.0707352 , 0.19077825, 0.24138073, 0.11529657,\n",
       "         0.3557732 , 0.18749461, 0.29405508, 0.42759114, 0.10042461,\n",
       "         0.27362195, 0.29884387, 0.19930355, 0.06017279, 0.11053978,\n",
       "         0.07360056, 0.26534448, 0.06696952, 0.12132881, 0.12162343,\n",
       "         0.17343639, 0.39033584, 0.12615229, 0.07673511, 0.18232976,\n",
       "         0.06793545, 0.03918176, 0.04230066, 0.45715767, 0.07819249,\n",
       "         0.07267833, 0.58486336, 0.23528395, 0.13619424, 0.17947055,\n",
       "         0.17646085, 0.35379807, 0.20168809, 0.03799524, 0.18091   ,\n",
       "         0.37534913, 0.2804621 , 0.10858806, 0.19495382, 0.3495467 ,\n",
       "         0.2481631 , 0.13864456, 0.16737477, 0.24517905, 0.06320113,\n",
       "         0.02764178, 0.58663953, 0.06396783, 0.62870166, 0.19584557,\n",
       "         0.16461779, 0.11856232, 0.49421814, 0.21465173, 0.0521948 ,\n",
       "         0.18374529, 0.36745644, 0.10934761, 0.06226489, 0.10468837,\n",
       "         0.70189734, 0.2119989 , 0.32973006, 0.55364389, 0.15726061,\n",
       "         0.07780966, 0.15866609, 0.05682105, 0.15193424, 0.56039156,\n",
       "         0.04740758, 0.31843831, 0.09853091, 0.27605918, 0.32106126,\n",
       "         0.13110271, 0.05369917, 0.11037289, 0.36076854, 0.21972883,\n",
       "         0.06293254, 0.06482486, 0.07516172, 0.06023344, 0.03269043,\n",
       "         0.19446997, 0.08706556, 0.09735483, 0.64303396, 0.09549936,\n",
       "         0.6293765 , 0.4614464 , 0.0922968 , 0.31106195, 0.10965687,\n",
       "         0.12777315, 0.13693376, 0.36233384, 0.3298334 , 0.22984996,\n",
       "         0.17359834, 0.0880143 , 0.14045698, 0.11707074, 0.02358057,\n",
       "         0.07752036, 0.14946045, 0.26657613, 0.08959026, 0.23942326,\n",
       "         0.55170994, 0.46276463, 0.22087446, 0.02061867, 0.1055614 ,\n",
       "         0.3536635 , 0.26424015, 0.09752271, 0.23274866, 0.26801094,\n",
       "         0.03724619, 0.46099463, 0.18229954, 0.28064516, 0.13343153,\n",
       "         0.07298058, 0.14962327, 0.26058396, 0.44232494, 0.49649508,\n",
       "         0.12188525, 0.43130167, 0.45755564, 0.22400184, 0.32285733,\n",
       "         0.23308562, 0.49290565, 0.40106553, 0.64547218, 0.21992811,\n",
       "         0.21564557, 0.59822716, 0.102414  , 0.29425757, 0.21866218]),\n",
       "  array([0.61133819, 0.45554292, 0.14667218, 0.16740667, 0.2277424 ,\n",
       "         0.04252663, 0.42711308, 0.1744579 , 0.57292811, 0.19003239,\n",
       "         0.18623881, 0.19680385, 0.29019434, 0.65337231, 0.42110185,\n",
       "         0.13049367, 0.09263993, 0.29744426, 0.14090237, 0.3484433 ,\n",
       "         0.15494174, 0.31997337, 0.37828768, 0.6582526 , 0.13897485,\n",
       "         0.21054181, 0.26119529, 0.10052969, 0.172133  , 0.06234734,\n",
       "         0.09948542, 0.32345332, 0.11825298, 0.07973691, 0.24619931,\n",
       "         0.13353519, 0.513409  , 0.18862177, 0.17634752, 0.17818408,\n",
       "         0.13058616, 0.14410471, 0.15452465, 0.26522041, 0.73131426,\n",
       "         0.58658415, 0.2524112 , 0.19869075, 0.06140405, 0.09217807,\n",
       "         0.41861699, 0.08608281, 0.27958903, 0.2607193 , 0.15441285,\n",
       "         0.32034035, 0.21628267, 0.34489199, 0.39329148, 0.07690585,\n",
       "         0.31932262, 0.37500792, 0.21916198, 0.12367169, 0.06237738,\n",
       "         0.0862077 , 0.28974624, 0.06323339, 0.25623558, 0.10738223,\n",
       "         0.20334495, 0.31034572, 0.10318581, 0.11918517, 0.27431568,\n",
       "         0.04933473, 0.03730993, 0.03514097, 0.52798309, 0.0702673 ,\n",
       "         0.05269393, 0.53947655, 0.13773913, 0.13555111, 0.14646953,\n",
       "         0.23498869, 0.27078999, 0.20164831, 0.02466802, 0.194023  ,\n",
       "         0.29995221, 0.36943226, 0.09487476, 0.33865214, 0.33883238,\n",
       "         0.26307218, 0.1601118 , 0.16200891, 0.27736915, 0.06587546,\n",
       "         0.04907501, 0.50428291, 0.08874131, 0.71437394, 0.14722558,\n",
       "         0.09720793, 0.12658284, 0.49882498, 0.31490535, 0.07076607,\n",
       "         0.13287276, 0.28315093, 0.18181811, 0.06521023, 0.19711252,\n",
       "         0.61974682, 0.17464949, 0.40578696, 0.51963252, 0.12535887,\n",
       "         0.12794072, 0.33812548, 0.04930328, 0.08986744, 0.47982109,\n",
       "         0.0663777 , 0.30498896, 0.06809425, 0.25197348, 0.22488753,\n",
       "         0.10846728, 0.07814749, 0.07160061, 0.48850451, 0.18920843,\n",
       "         0.06733282, 0.07154991, 0.07741133, 0.07126379, 0.04127417,\n",
       "         0.17968475, 0.12398439, 0.1527261 , 0.63934371, 0.07730474,\n",
       "         0.60780604, 0.51268346, 0.07911456, 0.28286838, 0.21028308,\n",
       "         0.10892408, 0.0788566 , 0.29251762, 0.36934553, 0.23061257,\n",
       "         0.16852204, 0.1110798 , 0.18283429, 0.07568493, 0.04185847,\n",
       "         0.07996676, 0.16239207, 0.34590507, 0.17337307, 0.34512137,\n",
       "         0.44769173, 0.50888327, 0.28540389, 0.01766723, 0.18766506,\n",
       "         0.35275   , 0.39958567, 0.06758341, 0.35585754, 0.17845879,\n",
       "         0.08617824, 0.55334145, 0.2249853 , 0.45601646, 0.0681242 ,\n",
       "         0.06647331, 0.1525365 , 0.25567909, 0.39297415, 0.45038925,\n",
       "         0.23916097, 0.44368396, 0.35336852, 0.20918381, 0.38058029,\n",
       "         0.19256071, 0.57874786, 0.3484012 , 0.59443347, 0.21169245,\n",
       "         0.23815419, 0.53982112, 0.15854391, 0.29364663, 0.18958695]),\n",
       "  array([0.67288859, 0.6058291 , 0.27777327, 0.08624271, 0.21892834,\n",
       "         0.07399322, 0.34869815, 0.15437534, 0.47735914, 0.09435913,\n",
       "         0.17007905, 0.17832886, 0.33758876, 0.65408591, 0.39106407,\n",
       "         0.18996513, 0.06136049, 0.19264361, 0.1682415 , 0.3213164 ,\n",
       "         0.14575015, 0.42349444, 0.45257843, 0.60598798, 0.11999408,\n",
       "         0.21234414, 0.20900874, 0.10501709, 0.1677488 , 0.0470582 ,\n",
       "         0.12659892, 0.32280679, 0.13840604, 0.05183223, 0.23251482,\n",
       "         0.24004379, 0.5965116 , 0.23698806, 0.19292565, 0.19130519,\n",
       "         0.12009885, 0.19414081, 0.18264674, 0.26500025, 0.72433906,\n",
       "         0.60110617, 0.21267583, 0.31502418, 0.03933494, 0.07312237,\n",
       "         0.50263423, 0.06891283, 0.29321788, 0.16779231, 0.09270401,\n",
       "         0.25146818, 0.11189661, 0.29404471, 0.36533818, 0.06200014,\n",
       "         0.37921322, 0.28267568, 0.10430759, 0.13030012, 0.11987937,\n",
       "         0.10667452, 0.22451658, 0.1092386 , 0.21493655, 0.16587357,\n",
       "         0.16304622, 0.37234408, 0.16191547, 0.10075603, 0.26358676,\n",
       "         0.07283823, 0.03660085, 0.06674509, 0.57494708, 0.09865171,\n",
       "         0.03625764, 0.63618755, 0.23858478, 0.07448735, 0.14118486,\n",
       "         0.16964604, 0.29669852, 0.18972944, 0.03077022, 0.17640474,\n",
       "         0.26793062, 0.3464876 , 0.12096145, 0.15805902, 0.25490474,\n",
       "         0.24393319, 0.121007  , 0.18860843, 0.33698104, 0.08995954,\n",
       "         0.08882649, 0.53805597, 0.07108846, 0.71562231, 0.12220183,\n",
       "         0.13450429, 0.1146817 , 0.34595156, 0.4041416 , 0.07548164,\n",
       "         0.19283969, 0.38748331, 0.08119444, 0.07988052, 0.13160531,\n",
       "         0.67501845, 0.18061263, 0.33616404, 0.54519466, 0.18073847,\n",
       "         0.11089159, 0.22534737, 0.04599942, 0.13335203, 0.58268552,\n",
       "         0.0986849 , 0.31672504, 0.12877515, 0.26430691, 0.31857238,\n",
       "         0.06548988, 0.02819659, 0.09291257, 0.54078462, 0.2174426 ,\n",
       "         0.05931944, 0.0905204 , 0.11754136, 0.07184332, 0.06068185,\n",
       "         0.13707173, 0.10214232, 0.14334915, 0.64902488, 0.11646524,\n",
       "         0.3978847 , 0.39628265, 0.0654809 , 0.29952632, 0.22073861,\n",
       "         0.13222335, 0.10554653, 0.25941135, 0.4010234 , 0.22810548,\n",
       "         0.14389777, 0.11215509, 0.18557132, 0.12434713, 0.0408095 ,\n",
       "         0.07620022, 0.11918786, 0.21683238, 0.10377976, 0.33646057,\n",
       "         0.64166275, 0.57326243, 0.28676101, 0.02217146, 0.17371428,\n",
       "         0.34887596, 0.35716417, 0.09521436, 0.40333951, 0.21719231,\n",
       "         0.09254874, 0.38505801, 0.22655378, 0.47230822, 0.10508657,\n",
       "         0.10235728, 0.15284483, 0.19731465, 0.34933688, 0.34285354,\n",
       "         0.16288761, 0.48146351, 0.32695149, 0.16863298, 0.45841726,\n",
       "         0.21755231, 0.43561155, 0.25568743, 0.64728261, 0.26774172,\n",
       "         0.17061217, 0.51654764, 0.12310345, 0.2588005 , 0.16181787]),\n",
       "  array([0.71537515, 0.45646892, 0.26404887, 0.1466651 , 0.22366227,\n",
       "         0.04191328, 0.37938034, 0.1545989 , 0.4258644 , 0.1357154 ,\n",
       "         0.16555682, 0.18944246, 0.27029801, 0.66586146, 0.41156221,\n",
       "         0.14929249, 0.09240343, 0.35011788, 0.09973687, 0.29207641,\n",
       "         0.20391521, 0.44822486, 0.48040273, 0.58240407, 0.12283408,\n",
       "         0.26947086, 0.21422486, 0.18889438, 0.17062172, 0.06819262,\n",
       "         0.14113194, 0.32393669, 0.11140588, 0.07131155, 0.22664931,\n",
       "         0.25184816, 0.54622984, 0.18058541, 0.17158728, 0.15981497,\n",
       "         0.07525325, 0.17222532, 0.22730584, 0.27654541, 0.67411141,\n",
       "         0.60975535, 0.17796014, 0.18930577, 0.04997553, 0.07085293,\n",
       "         0.51633833, 0.11777212, 0.28430265, 0.27162036, 0.1421811 ,\n",
       "         0.3097875 , 0.11936329, 0.43201343, 0.3301388 , 0.11026927,\n",
       "         0.34536079, 0.3677336 , 0.10925556, 0.13975568, 0.13114075,\n",
       "         0.06464523, 0.34950862, 0.09632188, 0.14993369, 0.15057849,\n",
       "         0.21232148, 0.28094357, 0.20479226, 0.08907348, 0.23617961,\n",
       "         0.07030306, 0.04331375, 0.04918519, 0.65455215, 0.08858772,\n",
       "         0.06135528, 0.54511727, 0.2309993 , 0.1501005 , 0.21195364,\n",
       "         0.12522908, 0.34137655, 0.22552344, 0.02087261, 0.2515347 ,\n",
       "         0.32190974, 0.35105303, 0.13693809, 0.24328266, 0.35915537,\n",
       "         0.21115822, 0.14806719, 0.20605663, 0.272935  , 0.06458803,\n",
       "         0.07842468, 0.61771698, 0.10614106, 0.67118177, 0.19983919,\n",
       "         0.13551233, 0.12299178, 0.4790086 , 0.19750487, 0.0823319 ,\n",
       "         0.17105772, 0.24106316, 0.11566517, 0.0958161 , 0.21068057,\n",
       "         0.63613887, 0.21866431, 0.34334387, 0.49141235, 0.13189467,\n",
       "         0.10062699, 0.32170197, 0.09324995, 0.09450199, 0.65258063,\n",
       "         0.03849766, 0.27473269, 0.1103878 , 0.28553528, 0.28353655,\n",
       "         0.07701111, 0.04389634, 0.08114517, 0.48025338, 0.24194806,\n",
       "         0.08405047, 0.06648042, 0.06237942, 0.09894881, 0.06567075,\n",
       "         0.21625585, 0.16557783, 0.13069994, 0.65122822, 0.07504345,\n",
       "         0.52418065, 0.49330133, 0.0929753 , 0.31040761, 0.16902117,\n",
       "         0.19225542, 0.11382655, 0.30403077, 0.32317924, 0.22436708,\n",
       "         0.14677439, 0.07541542, 0.19345586, 0.11914407, 0.06722329,\n",
       "         0.09150962, 0.1579737 , 0.31145547, 0.19166587, 0.36476821,\n",
       "         0.66375614, 0.48087171, 0.21585338, 0.02022971, 0.17535868,\n",
       "         0.35731458, 0.35135444, 0.1160184 , 0.43875023, 0.32457494,\n",
       "         0.05520472, 0.47160388, 0.17814094, 0.35066541, 0.08435104,\n",
       "         0.0706376 , 0.16428513, 0.31137821, 0.39587268, 0.42052503,\n",
       "         0.22555517, 0.45301468, 0.35285145, 0.18347591, 0.32020938,\n",
       "         0.23991327, 0.49205241, 0.28925381, 0.59691027, 0.25598171,\n",
       "         0.14969959, 0.46827104, 0.16005554, 0.26806338, 0.22746022]),\n",
       "  array([0.63715502, 0.56373319, 0.2444022 , 0.10937327, 0.26038039,\n",
       "         0.05564511, 0.37219397, 0.16258394, 0.50752523, 0.23482538,\n",
       "         0.14724738, 0.15647618, 0.3770757 , 0.67306964, 0.46149426,\n",
       "         0.14995008, 0.0715018 , 0.2782475 , 0.09434725, 0.29763693,\n",
       "         0.1882153 , 0.47630299, 0.47613906, 0.60191163, 0.10748859,\n",
       "         0.24294236, 0.20711536, 0.15629838, 0.21311863, 0.06344979,\n",
       "         0.13996066, 0.30288569, 0.08685703, 0.12338338, 0.22755522,\n",
       "         0.24695158, 0.57084034, 0.20506367, 0.21780331, 0.18806018,\n",
       "         0.08934868, 0.19803191, 0.20471262, 0.24879047, 0.57310126,\n",
       "         0.55827943, 0.22946489, 0.23594175, 0.0683216 , 0.09872095,\n",
       "         0.56191518, 0.07775573, 0.36560709, 0.28376034, 0.13436723,\n",
       "         0.29991095, 0.11857187, 0.45952982, 0.3863191 , 0.10423805,\n",
       "         0.36166755, 0.33997064, 0.22122805, 0.1215027 , 0.08131972,\n",
       "         0.05555861, 0.26850564, 0.10131761, 0.26622137, 0.17771669,\n",
       "         0.17524219, 0.38530825, 0.19689229, 0.11764406, 0.27463019,\n",
       "         0.08770907, 0.03354596, 0.04257532, 0.48719452, 0.0563725 ,\n",
       "         0.05114298, 0.6039054 , 0.2566341 , 0.13499897, 0.1264001 ,\n",
       "         0.25041972, 0.37518061, 0.21821432, 0.02176587, 0.21715525,\n",
       "         0.33717125, 0.39680169, 0.2125491 , 0.30618233, 0.37135963,\n",
       "         0.28336398, 0.12070929, 0.1952567 , 0.27745456, 0.05572553,\n",
       "         0.05805866, 0.56981321, 0.0852472 , 0.65481266, 0.22054071,\n",
       "         0.13720907, 0.08578973, 0.44220529, 0.34329122, 0.06247036,\n",
       "         0.21136171, 0.33829194, 0.21693749, 0.06495366, 0.12666645,\n",
       "         0.72819671, 0.19719129, 0.2980547 , 0.54870126, 0.11061443,\n",
       "         0.14307876, 0.31636966, 0.05707078, 0.129398  , 0.6505007 ,\n",
       "         0.05582691, 0.34932264, 0.12759202, 0.25070477, 0.25824003,\n",
       "         0.07842337, 0.04400231, 0.11288695, 0.40703322, 0.20954149,\n",
       "         0.06555291, 0.10228782, 0.0798738 , 0.08929953, 0.06313938,\n",
       "         0.17010858, 0.20916096, 0.15611903, 0.57818421, 0.16367316,\n",
       "         0.55401271, 0.521755  , 0.10816259, 0.27152081, 0.14363117,\n",
       "         0.10338691, 0.12662518, 0.33568309, 0.36808824, 0.28872227,\n",
       "         0.18681999, 0.07999173, 0.19548519, 0.11807853, 0.03555628,\n",
       "         0.10367098, 0.1860085 , 0.3322802 , 0.17150858, 0.32144554,\n",
       "         0.64246906, 0.54667622, 0.24069843, 0.01815906, 0.21919103,\n",
       "         0.35091509, 0.26140667, 0.06503249, 0.41365034, 0.280005  ,\n",
       "         0.10023269, 0.46140682, 0.18149682, 0.46757715, 0.1315494 ,\n",
       "         0.1007933 , 0.16030762, 0.30243697, 0.39699475, 0.39837369,\n",
       "         0.21684619, 0.37255718, 0.38328539, 0.18236613, 0.5330426 ,\n",
       "         0.29303267, 0.56485625, 0.40383573, 0.60505192, 0.28873941,\n",
       "         0.15481497, 0.55363029, 0.09395712, 0.36226568, 0.14210883]),\n",
       "  array([0.67255074, 0.53083269, 0.20023829, 0.0592084 , 0.16309893,\n",
       "         0.04971683, 0.30587174, 0.17690298, 0.46812998, 0.16038587,\n",
       "         0.1042987 , 0.17817612, 0.25259674, 0.61137697, 0.36196348,\n",
       "         0.15606609, 0.10590771, 0.21831242, 0.13835297, 0.10859453,\n",
       "         0.16317171, 0.45167118, 0.52021513, 0.6656133 , 0.07737739,\n",
       "         0.31708594, 0.27904017, 0.12883259, 0.205736  , 0.08969752,\n",
       "         0.10757647, 0.22204848, 0.11443463, 0.06708088, 0.21147393,\n",
       "         0.23993766, 0.48124558, 0.179712  , 0.12971267, 0.13493056,\n",
       "         0.07811494, 0.13257196, 0.16575355, 0.22115235, 0.63061175,\n",
       "         0.5199492 , 0.16103186, 0.22397898, 0.06088797, 0.08716875,\n",
       "         0.45271491, 0.08113524, 0.33208014, 0.13562837, 0.13628965,\n",
       "         0.22112325, 0.18094721, 0.29813268, 0.36266074, 0.12194776,\n",
       "         0.28603278, 0.30007933, 0.13891149, 0.09636304, 0.08055974,\n",
       "         0.06667505, 0.28799304, 0.07887832, 0.1479679 , 0.14642066,\n",
       "         0.21132411, 0.34925477, 0.16273654, 0.09945644, 0.26237117,\n",
       "         0.08320341, 0.06589634, 0.08068273, 0.65927566, 0.0930931 ,\n",
       "         0.06338783, 0.61817515, 0.14833676, 0.12078641, 0.10666699,\n",
       "         0.17764186, 0.3349982 , 0.20554277, 0.04073558, 0.21418534,\n",
       "         0.32891293, 0.26506237, 0.18533863, 0.16399276, 0.39449201,\n",
       "         0.20777215, 0.16369162, 0.14128054, 0.10262193, 0.05610411,\n",
       "         0.04067369, 0.6015705 , 0.09111877, 0.63756673, 0.11907839,\n",
       "         0.12701449, 0.12031785, 0.39914234, 0.29383348, 0.09512943,\n",
       "         0.19377553, 0.26459161, 0.17184132, 0.05236569, 0.15798254,\n",
       "         0.65568613, 0.21181091, 0.31806711, 0.47877392, 0.15278173,\n",
       "         0.11307984, 0.24454708, 0.04698982, 0.12914796, 0.59976341,\n",
       "         0.05578896, 0.28213148, 0.0745151 , 0.28054054, 0.30420989,\n",
       "         0.06255142, 0.03514932, 0.07933195, 0.4928649 , 0.22086914,\n",
       "         0.03848492, 0.05618013, 0.1101686 , 0.09939069, 0.04409169,\n",
       "         0.20317219, 0.11461949, 0.18730727, 0.62313178, 0.13400306,\n",
       "         0.55887903, 0.36203792, 0.06794754, 0.24911238, 0.15833592,\n",
       "         0.1804201 , 0.08292028, 0.19545987, 0.38531923, 0.26309012,\n",
       "         0.13384973, 0.08662174, 0.11897633, 0.11559073, 0.05667825,\n",
       "         0.05620208, 0.14706822, 0.29134181, 0.07122927, 0.2586485 ,\n",
       "         0.43739154, 0.50285082, 0.26762088, 0.02110137, 0.17611944,\n",
       "         0.37297896, 0.21843646, 0.09586133, 0.35123642, 0.11323433,\n",
       "         0.05889283, 0.4580386 , 0.2053085 , 0.24445208, 0.12413811,\n",
       "         0.08072378, 0.16706261, 0.31082572, 0.33303132, 0.42435836,\n",
       "         0.16274992, 0.39160529, 0.33206776, 0.2324537 , 0.38864429,\n",
       "         0.18651871, 0.33203395, 0.39987404, 0.63651676, 0.21527505,\n",
       "         0.12883505, 0.5018877 , 0.17964962, 0.25487546, 0.24537869]),\n",
       "  array([0.61613743, 0.454047  , 0.22734232, 0.09588441, 0.23176909,\n",
       "         0.07597368, 0.3501283 , 0.10504921, 0.41907018, 0.1689872 ,\n",
       "         0.18396242, 0.10484505, 0.25548976, 0.66154208, 0.50047617,\n",
       "         0.13979817, 0.05077957, 0.31524103, 0.05838941, 0.2628897 ,\n",
       "         0.08895525, 0.37756622, 0.50919095, 0.60647488, 0.05677256,\n",
       "         0.22925879, 0.18697102, 0.08243688, 0.08637648, 0.06268668,\n",
       "         0.07267809, 0.27424024, 0.09876192, 0.08933517, 0.18644169,\n",
       "         0.19536402, 0.50790928, 0.08045732, 0.15388676, 0.11188592,\n",
       "         0.08584472, 0.12366144, 0.11175365, 0.18266061, 0.70466254,\n",
       "         0.67394495, 0.22173327, 0.24404604, 0.0640405 , 0.05615417,\n",
       "         0.43691512, 0.05217126, 0.19045629, 0.11914924, 0.12996619,\n",
       "         0.16495105, 0.17123241, 0.18799529, 0.29468331, 0.07565428,\n",
       "         0.35395324, 0.27956225, 0.07433211, 0.07070321, 0.07721146,\n",
       "         0.07174316, 0.29715524, 0.0936977 , 0.20813563, 0.12328119,\n",
       "         0.16247787, 0.3482204 , 0.09741049, 0.12086066, 0.22281712,\n",
       "         0.06788454, 0.05173418, 0.05338064, 0.51296151, 0.06161178,\n",
       "         0.06486715, 0.4562929 , 0.22968598, 0.10192347, 0.11057386,\n",
       "         0.23470949, 0.29876217, 0.19698284, 0.02049516, 0.25667115,\n",
       "         0.34105181, 0.26233699, 0.14757769, 0.17783933, 0.39558794,\n",
       "         0.22503855, 0.10992733, 0.10672073, 0.21858072, 0.05407841,\n",
       "         0.0390454 , 0.52749076, 0.04218758, 0.56998822, 0.18236609,\n",
       "         0.11417343, 0.10635483, 0.30416134, 0.19441225, 0.06103922,\n",
       "         0.15530011, 0.1926066 , 0.16423843, 0.05968816, 0.1025939 ,\n",
       "         0.60478002, 0.23554245, 0.27279876, 0.49689071, 0.08625763,\n",
       "         0.09433206, 0.2311297 , 0.07793886, 0.10475821, 0.4878912 ,\n",
       "         0.04659754, 0.25341187, 0.06934259, 0.25446832, 0.21335793,\n",
       "         0.07705465, 0.03555897, 0.06182631, 0.48701005, 0.25404164,\n",
       "         0.07369768, 0.07499026, 0.07510907, 0.04632802, 0.02227904,\n",
       "         0.25188359, 0.12229095, 0.15744095, 0.51780302, 0.1442483 ,\n",
       "         0.6193306 , 0.38211976, 0.10628573, 0.23353586, 0.18059686,\n",
       "         0.15157716, 0.14348033, 0.23235094, 0.37309362, 0.22707638,\n",
       "         0.15681476, 0.09015785, 0.13001208, 0.04754067, 0.02898998,\n",
       "         0.08292289, 0.13325769, 0.28850722, 0.18767289, 0.13314299,\n",
       "         0.42451767, 0.50109639, 0.2170731 , 0.02876316, 0.14941863,\n",
       "         0.25665455, 0.26849298, 0.05630739, 0.31914339, 0.19729368,\n",
       "         0.05133832, 0.46110046, 0.25234469, 0.33779325, 0.08583435,\n",
       "         0.06310758, 0.1373038 , 0.262753  , 0.4279317 , 0.33164597,\n",
       "         0.15610706, 0.37895257, 0.43151665, 0.2748785 , 0.23122642,\n",
       "         0.18930808, 0.44795078, 0.33840882, 0.613104  , 0.20334803,\n",
       "         0.21617476, 0.57003037, 0.13579048, 0.28665626, 0.18330826]),\n",
       "  array([0.60419202, 0.42151683, 0.18894064, 0.11302152, 0.17830397,\n",
       "         0.0429744 , 0.26863417, 0.08849558, 0.38688736, 0.15824985,\n",
       "         0.10762354, 0.13389809, 0.20685264, 0.63600136, 0.37007515,\n",
       "         0.20252465, 0.0680976 , 0.28038227, 0.07568687, 0.30803322,\n",
       "         0.0863472 , 0.23058142, 0.25442092, 0.56460093, 0.11035685,\n",
       "         0.19523541, 0.32690785, 0.06829529, 0.12880481, 0.05549691,\n",
       "         0.07777716, 0.30977174, 0.04432179, 0.08370707, 0.17818102,\n",
       "         0.15005386, 0.46249779, 0.16971316, 0.12657174, 0.1544227 ,\n",
       "         0.12190026, 0.12024909, 0.17210528, 0.10931759, 0.69097723,\n",
       "         0.53486031, 0.17436905, 0.24836324, 0.06134778, 0.08297205,\n",
       "         0.45049397, 0.14496093, 0.24709841, 0.16151076, 0.11821409,\n",
       "         0.22260335, 0.19874069, 0.26948615, 0.38448266, 0.09111392,\n",
       "         0.32979186, 0.31181451, 0.13911025, 0.09727184, 0.08610728,\n",
       "         0.07077962, 0.25403492, 0.09599407, 0.13383534, 0.09649487,\n",
       "         0.21376897, 0.31999715, 0.15333706, 0.09608218, 0.21867914,\n",
       "         0.02513794, 0.04624946, 0.0577293 , 0.51599067, 0.07708717,\n",
       "         0.08656439, 0.45945892, 0.12023762, 0.05787599, 0.07021083,\n",
       "         0.16910454, 0.16944898, 0.18268223, 0.02061119, 0.29027843,\n",
       "         0.27457543, 0.27804138, 0.12846646, 0.13916695, 0.35202239,\n",
       "         0.27766794, 0.09977155, 0.1761591 , 0.24234008, 0.04868322,\n",
       "         0.04372553, 0.4501523 , 0.11997488, 0.55869991, 0.13471936,\n",
       "         0.10377177, 0.11807527, 0.28654853, 0.31201006, 0.04710766,\n",
       "         0.16053569, 0.21336578, 0.13486351, 0.05334922, 0.117867  ,\n",
       "         0.61779509, 0.20424073, 0.32603532, 0.51927361, 0.06231266,\n",
       "         0.1092022 , 0.20132248, 0.08675293, 0.1274947 , 0.54888066,\n",
       "         0.02531336, 0.31122251, 0.06896606, 0.18199562, 0.26183068,\n",
       "         0.06878813, 0.03253406, 0.0632158 , 0.4226787 , 0.12651602,\n",
       "         0.03708596, 0.06733617, 0.06411599, 0.03709176, 0.03842132,\n",
       "         0.17416001, 0.11453634, 0.13334647, 0.62606205, 0.10380742,\n",
       "         0.6360657 , 0.24165895, 0.06535228, 0.26477715, 0.16025847,\n",
       "         0.11003932, 0.10479687, 0.19210601, 0.34082089, 0.22082599,\n",
       "         0.11921279, 0.06118804, 0.14001275, 0.05001384, 0.02712599,\n",
       "         0.08951595, 0.23150382, 0.31154573, 0.06154647, 0.29678176,\n",
       "         0.383816  , 0.5637491 , 0.19517125, 0.01555522, 0.10453571,\n",
       "         0.31979197, 0.16272951, 0.05864685, 0.23505539, 0.21560651,\n",
       "         0.07061362, 0.50852236, 0.15300051, 0.39781303, 0.09361998,\n",
       "         0.05946877, 0.11322905, 0.27631535, 0.35861482, 0.34485937,\n",
       "         0.23843021, 0.34816842, 0.39673836, 0.14852359, 0.39269959,\n",
       "         0.19795974, 0.51359879, 0.33675915, 0.59907312, 0.20673971,\n",
       "         0.13541358, 0.56170627, 0.12150489, 0.34288708, 0.07249693]),\n",
       "  array([0.63152672, 0.46613149, 0.22347394, 0.10459945, 0.24939676,\n",
       "         0.06318776, 0.32075993, 0.11004031, 0.43724815, 0.10998081,\n",
       "         0.16372918, 0.1747435 , 0.28304225, 0.56957577, 0.44216923,\n",
       "         0.12085869, 0.12288918, 0.34139904, 0.08078873, 0.26846528,\n",
       "         0.14442421, 0.43338188, 0.37961742, 0.58677022, 0.0656765 ,\n",
       "         0.21346814, 0.24570584, 0.11629709, 0.21460763, 0.06260071,\n",
       "         0.15176947, 0.32679914, 0.11340252, 0.07337216, 0.2233812 ,\n",
       "         0.25845454, 0.49945252, 0.1902552 , 0.20453683, 0.17001898,\n",
       "         0.12083949, 0.13471474, 0.10621091, 0.21257723, 0.64714141,\n",
       "         0.57347907, 0.21521962, 0.267718  , 0.05963873, 0.07225301,\n",
       "         0.52022829, 0.09664142, 0.27564837, 0.21980921, 0.14782994,\n",
       "         0.37948527, 0.13200484, 0.34609663, 0.2833584 , 0.12132734,\n",
       "         0.34243996, 0.34385108, 0.12297793, 0.11025036, 0.11450496,\n",
       "         0.08891886, 0.33696244, 0.0833195 , 0.17904172, 0.09095098,\n",
       "         0.19016965, 0.29077438, 0.19907758, 0.13152853, 0.33421039,\n",
       "         0.06689119, 0.03805819, 0.0650178 , 0.57425823, 0.045153  ,\n",
       "         0.04026241, 0.64973177, 0.20934244, 0.14483118, 0.13567021,\n",
       "         0.17482591, 0.2953478 , 0.22964012, 0.01601554, 0.24614855,\n",
       "         0.31676492, 0.32108671, 0.14796688, 0.16535243, 0.31972262,\n",
       "         0.24454358, 0.10042319, 0.14460593, 0.27512466, 0.0451636 ,\n",
       "         0.04587985, 0.45056399, 0.06481816, 0.58468186, 0.12436933,\n",
       "         0.13450223, 0.14812194, 0.48195385, 0.22400137, 0.0694924 ,\n",
       "         0.13282252, 0.29896902, 0.12159558, 0.06695059, 0.12545001,\n",
       "         0.67179202, 0.21236463, 0.23355871, 0.55607606, 0.11822202,\n",
       "         0.11864881, 0.3071954 , 0.05065336, 0.21861559, 0.52968144,\n",
       "         0.06113113, 0.31767442, 0.10757572, 0.28037982, 0.30314464,\n",
       "         0.13587056, 0.04706659, 0.09496324, 0.52668375, 0.19300491,\n",
       "         0.08059352, 0.06271089, 0.09582415, 0.04556772, 0.05127466,\n",
       "         0.198613  , 0.16933641, 0.1684914 , 0.58383243, 0.10906671,\n",
       "         0.62452223, 0.4357594 , 0.13809822, 0.26082307, 0.12286803,\n",
       "         0.15619928, 0.11464383, 0.21938119, 0.3935473 , 0.25290553,\n",
       "         0.15437943, 0.10679425, 0.20236792, 0.10032019, 0.02752525,\n",
       "         0.08636812, 0.15045517, 0.23803993, 0.13537035, 0.32057128,\n",
       "         0.48056716, 0.61986915, 0.20022   , 0.02728574, 0.16212948,\n",
       "         0.37821983, 0.33121927, 0.08610578, 0.34031679, 0.23317992,\n",
       "         0.05400831, 0.44612141, 0.14875897, 0.32810748, 0.08430376,\n",
       "         0.07928119, 0.12431701, 0.25705798, 0.41942026, 0.42643718,\n",
       "         0.15865458, 0.28982157, 0.34116645, 0.26719393, 0.32951879,\n",
       "         0.19102104, 0.4412441 , 0.25675589, 0.56634904, 0.28893306,\n",
       "         0.22401807, 0.50852283, 0.09948948, 0.32095526, 0.19952405]),\n",
       "  array([0.59447233, 0.46781657, 0.12784469, 0.06491777, 0.22180919,\n",
       "         0.04020606, 0.33494476, 0.16989583, 0.43371236, 0.071368  ,\n",
       "         0.17377049, 0.13328672, 0.12895647, 0.68474513, 0.38928437,\n",
       "         0.18029754, 0.11915013, 0.25081257, 0.10553113, 0.25671741,\n",
       "         0.18709305, 0.42166433, 0.23730632, 0.50709167, 0.06971036,\n",
       "         0.25698821, 0.24283704, 0.08070791, 0.14151596, 0.05181326,\n",
       "         0.07302426, 0.20983868, 0.06064842, 0.05730598, 0.1534105 ,\n",
       "         0.20089046, 0.48900345, 0.1980044 , 0.19867492, 0.18341007,\n",
       "         0.11882163, 0.14272182, 0.15589014, 0.20890926, 0.71773078,\n",
       "         0.490648  , 0.19061558, 0.1882443 , 0.07154027, 0.08428737,\n",
       "         0.36504554, 0.10070209, 0.22548187, 0.12723523, 0.20981896,\n",
       "         0.21225105, 0.1014704 , 0.19573184, 0.32218871, 0.06902249,\n",
       "         0.2577595 , 0.28063062, 0.13502568, 0.12978082, 0.08539535,\n",
       "         0.07363938, 0.29581996, 0.09584098, 0.1642399 , 0.11776325,\n",
       "         0.15322353, 0.39487187, 0.16480162, 0.12750541, 0.25461962,\n",
       "         0.11316749, 0.05378932, 0.06350126, 0.56675383, 0.08595856,\n",
       "         0.05613798, 0.44829015, 0.13118696, 0.14860691, 0.11171002,\n",
       "         0.17543359, 0.24318229, 0.1273428 , 0.02493598, 0.21690468,\n",
       "         0.27735506, 0.2817543 , 0.14596885, 0.17433687, 0.11694438,\n",
       "         0.21312368, 0.13848625, 0.09070312, 0.25435547, 0.04759744,\n",
       "         0.05610604, 0.5200698 , 0.08073939, 0.58422976, 0.19273824,\n",
       "         0.10871663, 0.09313556, 0.20221409, 0.20113831, 0.07129833,\n",
       "         0.16468586, 0.22015086, 0.12635135, 0.068315  , 0.08340974,\n",
       "         0.62202915, 0.10193421, 0.27839189, 0.50720132, 0.10178126,\n",
       "         0.06881441, 0.28480585, 0.06755259, 0.06225   , 0.52547089,\n",
       "         0.04463433, 0.35418509, 0.10782149, 0.23403933, 0.2250931 ,\n",
       "         0.12766661, 0.05062791, 0.07093706, 0.4871423 , 0.23385254,\n",
       "         0.04449066, 0.09785957, 0.05150215, 0.0445187 , 0.06099793,\n",
       "         0.19585152, 0.15480426, 0.11351123, 0.62772159, 0.10233706,\n",
       "         0.5566675 , 0.43701324, 0.06049394, 0.22689464, 0.18077264,\n",
       "         0.13122553, 0.10558413, 0.24260303, 0.23381907, 0.25254879,\n",
       "         0.12247922, 0.09420075, 0.21100196, 0.04552322, 0.03318382,\n",
       "         0.09754587, 0.12752111, 0.25593   , 0.15975494, 0.35991545,\n",
       "         0.45513261, 0.57008827, 0.1948673 , 0.01669883, 0.14312683,\n",
       "         0.3088847 , 0.22353493, 0.07905725, 0.34282605, 0.18735628,\n",
       "         0.04431823, 0.53953254, 0.1498007 , 0.30322568, 0.10545352,\n",
       "         0.09372451, 0.14303482, 0.22405118, 0.39733677, 0.35120242,\n",
       "         0.18560729, 0.36123475, 0.38469117, 0.21222542, 0.38533945,\n",
       "         0.24614031, 0.44965799, 0.34715505, 0.55574819, 0.24509821,\n",
       "         0.16722822, 0.51741128, 0.11342561, 0.16843964, 0.24597785])]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "import src\n",
    "\n",
    "from src.runner import Runner\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Vanilla EuroSAT model configuration\n",
    "# -----------------------------------\n",
    "\n",
    "eurosat_model_cfg = dict(\n",
    "    type='EuroSATModel',\n",
    "    backbone_cfg=backbone_cfg,\n",
    "    head_cfg=dict(\n",
    "        type='FFN',\n",
    "        idims=64,\n",
    "        odims=10,  # EuroSAT has 10 classes\n",
    "        hidden_dims=1024,\n",
    "        nlayers=6,\n",
    "        dropout=0.2,\n",
    "    )\n",
    ")\n",
    "\n",
    "eurosat_vanilla = Runner(model=eurosat_model_cfg, dataloader_cfg=loading_cfg, dataset=eurosat_cfg, optim=optim_cfg, device='cuda:2', work_dir='results/eurosat_vanilla')\n",
    "eurosat_vanilla.run(mode='train', val_interval=1, log_interval=1, epochs=100, start_epoch=1)\n",
    "\n",
    "# -----------------------------------\n",
    "# Tiny ImageNet model configuration\n",
    "# -----------------------------------\n",
    "tiny_imnet_cfg = dict(\n",
    "    type='EuroSATModel',\n",
    "    backbone_cfg=backbone_cfg,\n",
    "    head_cfg=dict(\n",
    "        type='FFN',\n",
    "        idims=64,\n",
    "        odims=200,  # Tiny ImageNet has 200 classes\n",
    "        hidden_dims=1024,\n",
    "        nlayers=6,\n",
    "        dropout=0.2,\n",
    "    )\n",
    ")\n",
    "\n",
    "tiny_imnet = Runner(model=tiny_imnet_cfg, dataloader_cfg=loading_cfg, dataset=imagenet_cfg, optim=optim_cfg, device='cuda:2', work_dir='results/tiny_imnet')\n",
    "tiny_imnet.run(mode='train', val_interval=1, log_interval=1, epochs=100, start_epoch=1)\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# TFL EuroSAT model configuration\n",
    "# -----------------------------------\n",
    "tfl_eurosat_model_cfg = dict(\n",
    "    type='EuroSATModel',\n",
    "    backbone_cfg=backbone_cfg,\n",
    "    head_cfg=dict(\n",
    "        type='FFN',\n",
    "        idims=64,\n",
    "        odims=10,  # EuroSAT has 10 classes\n",
    "        hidden_dims=1024,\n",
    "        nlayers=6,\n",
    "        dropout=0.2,\n",
    "    ),\n",
    "    ckpt=dict(\n",
    "        path = tiny_imnet.best_model_path,\n",
    "        load_head=False,\n",
    "        load_backbone=True,\n",
    "        strict=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tfl_eurosat = Runner(model=tfl_eurosat_model_cfg, dataloader_cfg=loading_cfg, dataset=eurosat_cfg, optim=optim_cfg, device='cuda:2', work_dir='results/tfl_eurosat')\n",
    "tfl_eurosat.run(mode='train', val_interval=1, log_interval=1, epochs=100, start_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06981bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "transfer_model = torch.load('/mmdetection3d/PRIVATE/MLSP/results/eurosat/run_20250612-220000/best_model.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9048904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.build.registry import build_module, MODULES\n",
    "\n",
    "\n",
    "\n",
    "model_cfg = {\n",
    "    'type': 'EuroSATModel',\n",
    "    'backbone_cfg': {\n",
    "        'type': 'ResNet',\n",
    "        'idims': 3,\n",
    "        'odims': 64,\n",
    "        'base_dims': 12,\n",
    "        'arch': [2,2,2,2],\n",
    "        'dropout': 0.2,\n",
    "    },\n",
    "    'head_cfg': {\n",
    "        'type': 'FFN',\n",
    "        'idims': 64,\n",
    "        'odims': 10,  # EuroSAT has 10 classes\n",
    "        'hidden_dims': 1024,\n",
    "        'nlayers':6,\n",
    "        'dropout': 0.2,\n",
    "    },\n",
    "    'ckpt':{\n",
    "        'path': '/mmdetection3d/PRIVATE/MLSP/results/eurosat/run_20250612-220000/best_model.pth',\n",
    "        'load_head': False,\n",
    "        'load_backbone': True,\n",
    "        'strict': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = build_module(model_cfg, MODULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0683f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load only the backbone weights\n",
    "model.backbone.load_state_dict(transfer_model['backbone'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dbd646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No seed provided, using initial seed: 1971015095\n",
      "==================================\n",
      "     Model Parameters Summary     \n",
      "----------------------------------\n",
      "Trainable params     | 5,857,878\n",
      "Non-trainable params |         0\n",
      "Total params         | 5,857,878\n",
      "- Backbone params    | 1,582,668\n",
      "- Head params        | 4,275,210\n",
      "==================================\n",
      "Epoch 001/100 | Iter 19/19 | [██████████] |  | loss: 1.3158 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 2.2864 --> F1: 0.0880 | mAP: 0.2361\n",
      "Model saved to results/imagenet/run_20250612-220544/best_model.pth\n",
      "Best model saved at epoch 1 with val_loss 2.2327\n",
      "Epoch 002/100 | Iter 19/19 | [██████████] |  | loss: 1.0969 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 1.3027 --> F1: 0.4366 | mAP: 0.5032\n",
      "Model saved to results/imagenet/run_20250612-220544/best_model.pth\n",
      "Best model saved at epoch 2 with val_loss 2.0395\n",
      "Epoch 003/100 | Iter 19/19 | [██████████] |  | loss: 0.9099 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 1.4188 --> F1: 0.4444 | mAP: 0.5264\n",
      "Model saved to results/imagenet/run_20250612-220544/best_model.pth\n",
      "Best model saved at epoch 3 with val_loss 2.0085\n",
      "Epoch 004/100 | Iter 19/19 | [██████████] |  | loss: 0.9433 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 0.9702 --> F1: 0.6533 | mAP: 0.7129\n",
      "Model saved to results/imagenet/run_20250612-220544/best_model.pth\n",
      "Best model saved at epoch 4 with val_loss 1.8507\n",
      "Epoch 005/100 | Iter 19/19 | [██████████] |  | loss: 0.7517 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 0.7788 --> F1: 0.7127 | mAP: 0.7707\n",
      "Model saved to results/imagenet/run_20250612-220544/best_model.pth\n",
      "Best model saved at epoch 5 with val_loss 1.8171\n",
      "Epoch 006/100 | Iter 19/19 | [██████████] |  | loss: 0.7013 | lr: 1.0000e-03\n",
      "Evaluating | Iter 5400/5400 | [>>>>>>>>>>] |  100.00% | val_loss: 0.9327 --> F1: 0.6511 | mAP: 0.7468\n",
      "Epoch 007/100 | Iter 19/19 | [██████████] |  | loss: 0.5398 | lr: 1.0000e-03\n",
      "Evaluating | Iter 3701/5400 | [>>>>>>----] |  68.54% | val_loss: 0.7092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 61, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m runner_imnet = Runner(model=model, dataloader_cfg=loading_cfg, dataset=data_cfg, optim=optim_cfg, device=\u001b[33m'\u001b[39m\u001b[33mcuda:2\u001b[39m\u001b[33m'\u001b[39m, work_dir=\u001b[33m'\u001b[39m\u001b[33mresults/imagenet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mrunner_imnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/runner/runner.py:138\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, mode, val_interval, log_interval, epochs, start_epoch)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03mMain entry point for running the model.\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m    dict: History of training/validation metrics.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluate(\u001b[38;5;28mself\u001b[39m.val_data, batch_size=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/runner/runner.py:168\u001b[39m, in \u001b[36mRunner._train_loop\u001b[39m\u001b[34m(self, start, epochs, val_interval, log_interval, abort_condition)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28mself\u001b[39m.history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % val_interval == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     evals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_dir:\n\u001b[32m    171\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m evals[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m] < \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m], default=\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/runner/runner.py:314\u001b[39m, in \u001b[36mRunner.evaluate\u001b[39m\u001b[34m(self, dataset, epoch, batch_size, loss)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, epoch=\u001b[38;5;28;01mNone\u001b[39;00m, batch_size=\u001b[32m1\u001b[39m, loss=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    312\u001b[39m     evaluator = build_module(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mBaseEvaluator\u001b[39m\u001b[33m'\u001b[39m, device=\u001b[38;5;28mself\u001b[39m.device, batch_size=batch_size, dataset=dataset, model=\u001b[38;5;28mself\u001b[39m.model), EVALUATORS) \u001b[38;5;66;03m# Build evaluator from config\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     y_true, y_pred, y_scores = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#predict labels and scores\u001b[39;00m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss:\n\u001b[32m    316\u001b[39m         val_loss = \u001b[38;5;28mself\u001b[39m.criterion(torch.tensor(y_scores), torch.tensor(y_true)).item() \u001b[38;5;66;03m# calculate loss if requested (for model saving and overfitting detection)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mmdetection3d/PRIVATE/MLSP/src/evaluators/base_evaluator.py:48\u001b[39m, in \u001b[36mBaseEvaluator.predict\u001b[39m\u001b[34m(self, loss, log_interval)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataloader):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         imgs = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m         labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     50\u001b[39m         logits = \u001b[38;5;28mself\u001b[39m.model(imgs)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "runner_tfl = Runner(model=model, dataloader_cfg=loading_cfg, dataset=data_cfg, optim=optim_cfg, device='cuda:2', work_dir='results/imagenet')\n",
    "runner_tfl.run(mode='train', val_interval=1, log_interval=1, epochs=100, start_epoch=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
